{
    "garbage_collector": "Parallel",
    "jdk": "HotSpot_21.0.4",
    "benchmark_group": "Renaissance",
    "benchmark_name": "page-rank",
    "heap_size": "512",
    "error": "Error code not found: 1\n18:25:40.638 WARN  [dispatcher-HeartbeatReceiver] org.apache.spark.HeartbeatReceiver - Removing executor driver with no recent heartbeats: 133871 ms exceeds timeout 120000 ms\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.lang.StringUTF16.compress(StringUTF16.java:161)\n\tat java.base/java.lang.String.<init>(String.java:4768)\n\tat java.base/java.lang.String.<init>(String.java:303)\n\tat java.base/java.io.BufferedReader.implReadLine(BufferedReader.java:403)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:347)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:436)\n\tat scala.io.BufferedSource$BufferedLineIterator.hasNext(BufferedSource.scala:73)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:653)\n\tat scala.collection.immutable.List.prependedAll(List.scala:155)\n\tat scala.collection.immutable.List$.from(List.scala:684)\n\tat scala.collection.immutable.List$.from(List.scala:681)\n\tat scala.collection.SeqFactory$Delegate.from(Factory.scala:306)\n\tat scala.collection.immutable.Seq$.from(Seq.scala:42)\n\tat scala.collection.IterableOnceOps.toSeq(IterableOnce.scala:1326)\n\tat scala.collection.IterableOnceOps.toSeq$(IterableOnce.scala:1326)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1300)\n\tat org.renaissance.apache.spark.PageRank.copyLinesToFile(PageRank.scala:87)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:114)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x0000746a2411c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000746a24004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000746a2400a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n18:25:40.643 WARN  [dispatcher-HeartbeatReceiver] org.apache.spark.rpc.netty.NettyRpcEnv - Ignored message: true\n18:25:40.644 WARN  [kill-executor-thread] org.apache.spark.SparkContext - Killing executors is not supported by current scheduler.\n",
    "avg_cpu_usage": 59.5,
    "avg_cpu_time": 61.1,
    "avg_io_time": 0.0,
    "p90_io": 0.0,
    "number_of_pauses": 0,
    "total_pause_time": 0,
    "avg_pause_time": 0,
    "pauses_per_category": {},
    "total_pause_time_per_category": {},
    "avg_pause_time_per_category": {},
    "p90_pause_time": 0,
    "throughput": 0
}