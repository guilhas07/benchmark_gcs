{
    "garbage_collector": "Parallel",
    "jdk": "HotSpot_21.0.4",
    "benchmark_group": "Renaissance",
    "benchmark_name": "naive-bayes",
    "heap_size": "512",
    "error": "Error code not found: 52\n18:32:47.004 WARN  [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.storage.BlockManager - Block rdd_3_7 could not be removed as it was not found on disk or in memory\n18:32:47.169 ERROR [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.executor.Executor - Exception in task 7.0 in stage 0.0 (TID 7)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.build(ColumnBuilder.scala:81) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build(NullableColumnBuilder.scala:67) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build$(NullableColumnBuilder.scala:66) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.$anonfun$next$5(InMemoryRelation.scala:115) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1$$Lambda/0x00007982dbeb65c0.apply(Unknown Source) ~[?:?]\n\tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:934) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:114) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007982dbb2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007982dbbf2e20.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n18:32:48.072 ERROR [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#83,Executor task launch worker for task 7.0 in stage 0.0 (TID 7),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.build(ColumnBuilder.scala:81) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build(NullableColumnBuilder.scala:67) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build$(NullableColumnBuilder.scala:66) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.$anonfun$next$5(InMemoryRelation.scala:115) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1$$Lambda/0x00007982dbeb65c0.apply(Unknown Source) ~[?:?]\n\tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:934) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:114) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007982dbb2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007982dbbf2e20.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n",
    "avg_cpu_usage": 43.2,
    "avg_cpu_time": 59.0,
    "avg_io_time": 0.0,
    "p90_io": 0.0,
    "number_of_pauses": 0,
    "total_pause_time": 0,
    "avg_pause_time": 0,
    "pauses_per_category": {},
    "total_pause_time_per_category": {},
    "avg_pause_time_per_category": {},
    "p90_pause_time": 0,
    "throughput": 0
}