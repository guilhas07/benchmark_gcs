{
    "jdk": "Graal",
    "failed_benchmarks": {
        "256": {
            "h2": [
                [
                    "G1",
                    "Error code not found: 255\njava.lang.reflect.InvocationTargetException\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:237)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: org.h2.jdbc.JdbcSQLNonTransientConnectionException: Out of memory.; SQL statement:\n\n\nALTER TABLE ORDERLINE ADD CONSTRAINT\n    ORDERLINE_PK PRIMARY KEY(OL_W_ID, OL_D_ID, OL_O_ID, OL_NUMBE [90108-220]\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:690)\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:489)\n\tat org.h2.message.DbException.get(DbException.java:212)\n\tat org.h2.message.DbException.convert(DbException.java:401)\n\tat org.h2.command.Command.executeUpdate(Command.java:262)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createIndexes(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 8 more\nCaused by: java.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\n\tat org.h2.mvstore.Page$NonLeaf.setChild(Page.java:1197)\n\tat org.h2.mvstore.MVMap.replacePage(MVMap.java:1360)\n\tat org.h2.mvstore.MVMap.operate(MVMap.java:1863)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:363)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:350)\n\tat org.h2.mvstore.tx.TransactionMap.put(TransactionMap.java:265)\n\tat org.h2.mvstore.db.MVSecondaryIndex.add(MVSecondaryIndex.java:188)\n\tat org.h2.mvstore.db.MVTable.addRowsToIndex(MVTable.java:723)\n\tat org.h2.mvstore.db.MVTable.rebuildIndexBuffered(MVTable.java:467)\n\tat org.h2.mvstore.db.MVTable.rebuildIndex(MVTable.java:387)\n\tat org.h2.mvstore.db.MVTable.addIndex(MVTable.java:367)\n\tat org.h2.command.ddl.AlterTableAddConstraint.tryUpdate(AlterTableAddConstraint.java:149)\n\tat org.h2.command.ddl.AlterTableAddConstraint.update(AlterTableAddConstraint.java:74)\n\tat org.h2.command.ddl.AlterTable.update(AlterTable.java:46)\n\tat org.h2.command.CommandContainer.update(CommandContainer.java:169)\n\tat org.h2.command.Command.executeUpdate(Command.java:252)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createIndexes(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeVirtual(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007c5a9c01b000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 255\njava.lang.reflect.InvocationTargetException\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:237)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: org.h2.jdbc.JdbcSQLNonTransientConnectionException: Out of memory.; SQL statement:\n\n\nALTER TABLE STOCK ADD CONSTRAINT\n    STOCK_PK PRIMARY KEY (S_W_ID, S_I_I [90108-220]\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:690)\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:489)\n\tat org.h2.message.DbException.get(DbException.java:212)\n\tat org.h2.message.DbException.convert(DbException.java:401)\n\tat org.h2.command.Command.executeUpdate(Command.java:262)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createIndexes(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 8 more\nCaused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.lang.Object.clone(Native Method)\n\tat org.h2.mvstore.Page.clone(Page.java:392)\n\tat org.h2.mvstore.Page.copy(Page.java:381)\n\tat org.h2.mvstore.MVMap.operate(MVMap.java:1828)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:363)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:350)\n\tat org.h2.mvstore.tx.TransactionMap.put(TransactionMap.java:265)\n\tat org.h2.mvstore.db.MVSecondaryIndex.add(MVSecondaryIndex.java:188)\n\tat org.h2.mvstore.db.MVTable.addRowsToIndex(MVTable.java:723)\n\tat org.h2.mvstore.db.MVTable.rebuildIndexBuffered(MVTable.java:467)\n\tat org.h2.mvstore.db.MVTable.rebuildIndex(MVTable.java:387)\n\tat org.h2.mvstore.db.MVTable.addIndex(MVTable.java:367)\n\tat org.h2.command.ddl.AlterTableAddConstraint.tryUpdate(AlterTableAddConstraint.java:149)\n\tat org.h2.command.ddl.AlterTableAddConstraint.update(AlterTableAddConstraint.java:74)\n\tat org.h2.command.ddl.AlterTable.update(AlterTable.java:46)\n\tat org.h2.command.CommandContainer.update(CommandContainer.java:169)\n\tat org.h2.command.Command.executeUpdate(Command.java:252)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createIndexes(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeVirtual(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007b2f28019800.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\"\n"
                ]
            ],
            "als": [
                [
                    "G1",
                    "Error code not found: 1\n12:23:14.222 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n13:49:25.023 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n15:13:38.039 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "chi-square": [
                [
                    "G1",
                    "Error code not found: 1\n12:20:18.892 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n13:37:13.127 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n15:08:45.087 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "dec-tree": [
                [
                    "G1",
                    "Error code not found: 1\n12:22:46.998 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n13:39:18.266 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n15:13:21.494 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "gauss-mix": [
                [
                    "G1",
                    "Error code not found: 1\n12:23:52.209 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n13:50:03.818 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n15:14:23.842 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "log-regression": [
                [
                    "G1",
                    "Error code not found: 1\n12:23:48.842 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n13:50:00.615 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n15:14:20.244 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "movie-lens": [
                [
                    "G1",
                    "Error code not found: 1\n12:20:00.382 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n13:36:57.164 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n15:08:28.750 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "naive-bayes": [
                [
                    "G1",
                    "Error code not found: 1\n12:23:10.875 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n13:49:21.647 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n15:13:34.638 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"neo4j.Scheduler-1\"\nException in thread \"neo4j.VmPauseMonitor-1\" java.lang.OutOfMemoryError: Java heap space\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat play.api.libs.json.jackson.JsValueDeserializer.parseBigDecimal(JacksonJson.scala:172)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:200)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:101)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007eccac11bbe0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007eccac004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007eccac00d800.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"neo4j.VmPauseMonitor-1\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"neo4j.Scheduler-1\"\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\n"
                ]
            ],
            "page-rank": [
                [
                    "G1",
                    "Error code not found: 1\n12:17:00.285 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n13:34:25.903 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n15:07:49.633 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "reactors": [
                [
                    "G1",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-reanimator\"\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-1\" java.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\nFailed to load benchmark 'reactors': Java heap space\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-7\" java.lang.OutOfMemoryError: GC overhead limit exceeded\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-2\" java.lang.NoClassDefFoundError: Could not initialize class java.lang.StackTraceElement$HashedModules\njava.lang.NoClassDefFoundError: Could not initialize class java.lang.StackTraceElement$HashedModules\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-2\" java.lang.NoClassDefFoundError: Could not initialize class java.lang.StackTraceElement$HashedModules\nFailed to load benchmark 'reactors': GC overhead limit exceeded\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-reanimator\"\nFailed to load benchmark 'reactors': Java heap space\n"
                ]
            ],
            "kafka": [
                [
                    "Parallel",
                    "Error code not found: 3\n===== DaCapo 23.11-chopin kafka starting warmup 1 =====\nStarting 1000000 requests...\nCompleted requests\nFinished\n===== DaCapo 23.11-chopin kafka completed warmup 1 in 16744 msec =====\n===== DaCapo 23.11-chopin kafka starting warmup 2 =====\nStarting 1000000 requests...\n"
                ]
            ],
            "akka-uct": [
                [
                    "Parallel",
                    "Error code not found: 255\nUncaught error from thread [UCT-akka.actor.default-dispatcher-19]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\nUncaught error from thread [UCT-akka.actor.default-dispatcher-13]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat scala.reflect.ClassTag$cache$.computeTag(ClassTag.scala:129)\n\tat scala.reflect.ClassTag$.apply(ClassTag.scala:161)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateUrgentChildren(UctAkkaActorBenchmark.scala:323)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:249)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-18]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat akka.dispatch.Mailboxes.getMailboxType(Mailboxes.scala:148)\n\tat akka.actor.LocalActorRefProvider.actorOf(ActorRefProvider.scala:699)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:312)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateUrgentChildren(UctAkkaActorBenchmark.scala:323)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:249)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\nUncaught error from thread [UCT-akka.actor.internal-dispatcher-4]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-14]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-20]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-15]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\nRuntime.exit(-1) logging failed: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-10]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-17]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [Uncaught error from thread [UCT-akka.actor.default-dispatcher-21]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-7]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n"
                ],
                [
                    "Z",
                    "Error code not found: 255\nUncaught error from thread [UCT-akka.actor.default-dispatcher-15]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.RedBlackTree$Tree.withRight(RedBlackTree.scala:690)\n\tat scala.collection.immutable.RedBlackTree$.balanceRight(RedBlackTree.scala:403)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.update(RedBlackTree.scala:175)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.reserve(ChildrenContainer.scala:135)\n\tat akka.actor.dungeon.Children.reserveChild(Children.scala:146)\n\tat akka.actor.dungeon.Children.reserveChild$(Children.scala:22)\n\tat akka.actor.ActorCell.reserveChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:299)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateUrgentChildren(UctAkkaActorBenchmark.scala:323)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:249)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\nUncaught error from thread [UCT-akka.actor.default-dispatcher-9]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.RedBlackTree$Tree.withLeft(RedBlackTree.scala:681)\n\tat scala.collection.immutable.RedBlackTree$.balanceLeft(RedBlackTree.scala:357)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.update(RedBlackTree.scala:175)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.reserve(ChildrenContainer.scala:135)\n\tat akka.actor.dungeon.Children.reserveChild(Children.scala:146)\n\tat akka.actor.dungeon.Children.reserveChild$(Children.scala:22)\n\tat akka.actor.ActorCell.reserveChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:299)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n"
                ]
            ],
            "scala-stm-bench7": [
                [
                    "Parallel",
                    "Return code -9: Process was killed due to timeout\nSetup start...\nSetting up the design library:\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nSetup start...\nSetting up the design library:\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Thread-2\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\"\n"
                ]
            ]
        },
        "512": {
            "h2": [
                [
                    "G1",
                    "Return code -9: Process was killed due to timeout\n===== DaCapo 23.11-chopin h2 starting warmup 1 =====\nStarting 100000 requests...\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 255\njava.lang.reflect.InvocationTargetException\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:237)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: org.h2.jdbc.JdbcSQLNonTransientConnectionException: Out of memory.; SQL statement:\n\n\nALTER TABLE ORDERLINE ADD CONSTRAINT\n    OL_O_FK FOREIGN KEY (OL_W_ID, OL_D_ID, OL_O_ID) REFERENCES ORDE [90108-220]\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:690)\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:489)\n\tat org.h2.message.DbException.get(DbException.java:212)\n\tat org.h2.message.DbException.convert(DbException.java:401)\n\tat org.h2.command.Command.executeUpdate(Command.java:262)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createConstraints(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 8 more\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.util.Arrays.copyOf(Arrays.java:3513)\n\tat java.base/java.util.Arrays.copyOf(Arrays.java:3482)\n\tat java.base/java.util.ArrayList.grow(ArrayList.java:237)\n\tat java.base/java.util.ArrayList.grow(ArrayList.java:244)\n\tat java.base/java.util.ArrayList.add(ArrayList.java:483)\n\tat java.base/java.util.ArrayList.add(ArrayList.java:496)\n\tat org.h2.result.LocalResult.addRowInternal(LocalResult.java:431)\n\tat org.h2.result.LocalResult.addRow(LocalResult.java:410)\n\tat org.h2.command.query.Select.queryFlat(Select.java:730)\n\tat org.h2.command.query.Select.queryWithoutCache(Select.java:833)\n\tat org.h2.command.query.Query.queryWithoutCacheLazyCheck(Query.java:197)\n\tat org.h2.command.query.Query.query(Query.java:520)\n\tat org.h2.command.query.Query.query(Query.java:483)\n\tat org.h2.index.QueryExpressionIndex.find(QueryExpressionIndex.java:269)\n\tat org.h2.index.QueryExpressionIndex.find(QueryExpressionIndex.java:152)\n\tat org.h2.index.IndexCursor.find(IndexCursor.java:166)\n\tat org.h2.table.TableFilter.next(TableFilter.java:394)\n\tat org.h2.command.query.Select$LazyResultQueryFlat.fetchNextRow(Select.java:1843)\n\tat org.h2.result.LazyResult.hasNext(LazyResult.java:78)\n\tat org.h2.result.FetchedResult.next(FetchedResult.java:34)\n\tat org.h2.command.query.Select.queryFlat(Select.java:728)\n\tat org.h2.command.query.Select.queryWithoutCache(Select.java:833)\n\tat org.h2.command.query.Query.queryWithoutCacheLazyCheck(Query.java:197)\n\tat org.h2.command.query.Query.query(Query.java:520)\n\tat org.h2.command.query.Query.query(Query.java:483)\n\tat org.h2.constraint.ConstraintReferential.checkExistingData(ConstraintReferential.java:610)\n\tat org.h2.command.ddl.AlterTableAddConstraint.tryUpdate(AlterTableAddConstraint.java:288)\n\tat org.h2.command.ddl.AlterTableAddConstraint.update(AlterTableAddConstraint.java:74)\n\tat org.h2.command.ddl.AlterTable.update(AlterTable.java:46)\n\tat org.h2.command.CommandContainer.update(CommandContainer.java:169)\n\tat org.h2.command.Command.executeUpdate(Command.java:252)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\"\n"
                ]
            ],
            "naive-bayes": [
                [
                    "G1",
                    "Error code not found: 52\n12:34:49.230 WARN  [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] org.apache.spark.storage.BlockManager - Block rdd_3_1 could not be removed as it was not found on disk or in memory\n12:34:49.394 ERROR [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] org.apache.spark.executor.Executor - Exception in task 1.0 in stage 0.0 (TID 1)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x000075cf00b2f2a8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000075cf00bf62b8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n12:34:49.634 ERROR [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#82,Executor task launch worker for task 1.0 in stage 0.0 (TID 1),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x000075cf00b2f2a8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000075cf00bf62b8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 52\n14:08:17.719 WARN  [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.storage.BlockManager - Block rdd_3_7 could not be removed as it was not found on disk or in memory\n14:08:17.933 ERROR [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.executor.Executor - Exception in task 7.0 in stage 0.0 (TID 7)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007d1ad8b2f2a8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007d1ad8bf4fd8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n14:08:18.817 ERROR [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#83,Executor task launch worker for task 7.0 in stage 0.0 (TID 7),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007d1ad8b2f2a8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007d1ad8bf4fd8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n"
                ],
                [
                    "Z",
                    "Error code not found: 52\n15:42:30.624 WARN  [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.storage.BlockManager - Block rdd_3_3 could not be removed as it was not found on disk or in memory\n15:42:30.878 ERROR [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.executor.Executor - Exception in task 3.0 in stage 0.0 (TID 3)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x0000000080c1f2c8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x0000000080ce76a0.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n15:42:31.246 ERROR [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#83,Executor task launch worker for task 3.0 in stage 0.0 (TID 3),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x0000000080c1f2c8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x0000000080ce76a0.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n"
                ]
            ],
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.allocateTable(LongObjectHashMap.java:3022)\n\tat org.neo4j.collection.trackable.HeapTrackingLongObjectHashMap.allocateTable(HeapTrackingLongObjectHashMap.java:62)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehash(LongObjectHashMap.java:2908)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehashAndGrow(LongObjectHashMap.java:2900)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.addKeyValueAtIndex(LongObjectHashMap.java:2742)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.getIfAbsentPut(LongObjectHashMap.java:2357)\n\tat org.neo4j.kernel.impl.api.state.TxState.getOrCreateNodeState(TxState.java:673)\n\tat org.neo4j.kernel.impl.api.state.TxState.getOrCreateNodeStateLabelDiffSets(TxState.java:337)\n\tat org.neo4j.kernel.impl.api.state.TxState.nodeDoAddLabel(TxState.java:499)\n\tat org.neo4j.kernel.impl.newapi.Operations.checkConstraintsAndAddLabelToNode(Operations.java:420)\n\tat org.neo4j.kernel.impl.newapi.Operations.nodeCreateWithLabels(Operations.java:276)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.createNode(TransactionImpl.java:208)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.$anonfun$populateVertices$1(AnalyticsBenchmark.scala:73)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.$anonfun$populateVertices$1$adapted(AnalyticsBenchmark.scala:72)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark$$Lambda/0x0000774218650000.apply(Unknown Source)\n\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)\n\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:933)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:72)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000077421811bbe0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000774218004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000077421800d800.invoke(LambdaForm$MH)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:202)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:102)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000074fc4811bbe0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x000074fc48004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000074fc4800d800.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Return code -9: Process was killed due to timeout\nException in thread \"neo4j.Scheduler-1\" java.lang.OutOfMemoryError: Java heap space\nException in thread \"neo4j.IndexSampling-3\" java.lang.OutOfMemoryError: Java heap space\nException in thread \"neo4j.IndexSampling-5\" Exception in thread \"neo4j.IndexSampling-6\" java.lang.OutOfMemoryError: Java heap space\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"neo4j.IndexSampling-5\"\nException in thread \"neo4j.IndexSampling-8\" java.lang.OutOfMemoryError: Java heap space\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\n"
                ]
            ],
            "page-rank": [
                [
                    "G1",
                    "Error code not found: 1\nException in thread \"Spark Context Cleaner\" java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1362)\n\tat org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189)\n\tat org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79)\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\nException in thread \"RemoteBlock-temp-file-clean-thread\" java.lang.OutOfMemoryError: Java heap space\n\tat java.base/jdk.internal.misc.Unsafe.allocateInstance(Native Method)\n\tat java.base/java.lang.invoke.DirectMethodHandle.allocateInstance(DirectMethodHandle.java:501)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.newInvokeSpecial(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n\tat org.apache.spark.storage.BlockManager$RemoteBlockDownloadFileManager.org$apache$spark$storage$BlockManager$RemoteBlockDownloadFileManager$$keepCleaning(BlockManager.scala:2230)\n\tat org.apache.spark.storage.BlockManager$RemoteBlockDownloadFileManager$$anon$2.run(BlockManager.scala:2196)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Spark Context Cleaner\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"RemoteBlock-temp-file-clean-thread\"\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n"
                ]
            ],
            "reactors": [
                [
                    "Parallel",
                    "Error code not found: 1\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.lang.Class.getDeclaredConstructors0(Native Method)\n\tat java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3549)\n\tat java.base/java.lang.Class.getDeclaredConstructors(Class.java:2727)\n\tat io.reactors.Platform$Reflect$.matchingConstructor(Platform.scala:223)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:191)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:667)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.pollPool(JvmScheduler.scala:103)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.postschedule(JvmScheduler.scala:150)\n\tat io.reactors.JvmScheduler$Executed.postschedule(JvmScheduler.scala:273)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:202)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/jdk.internal.org.objectweb.asm.MethodWriter.visitFrameStart(MethodWriter.java:1855)\n\tat java.base/jdk.internal.org.objectweb.asm.Frame.accept(Frame.java:1412)\n\tat java.base/jdk.internal.org.objectweb.asm.MethodWriter.computeAllFrames(MethodWriter.java:1615)\n\tat java.base/jdk.internal.org.objectweb.asm.MethodWriter.visitMaxs(MethodWriter.java:1579)\n\tat java.base/java.lang.invoke.InvokerBytecodeGenerator.methodEpilogue(InvokerBytecodeGenerator.java:287)\n\tat java.base/java.lang.invoke.InvokerBytecodeGenerator.addMethod(InvokerBytecodeGenerator.java:870)\n\tat java.base/java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCodeBytes(InvokerBytecodeGenerator.java:754)\n\tat java.base/java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCode(InvokerBytecodeGenerator.java:712)\n\tat java.base/java.lang.invoke.LambdaForm.compileToBytecode(LambdaForm.java:849)\n\tat java.base/java.lang.invoke.LambdaForm.prepare(LambdaForm.java:807)\n\tat java.base/java.lang.invoke.MethodHandle.<init>(MethodHandle.java:482)\n\tat java.base/java.lang.invoke.BoundMethodHandle.<init>(BoundMethodHandle.java:52)\n\tat java.base/java.lang.invoke.BoundMethodHandle$Species_LL.<init>(java/lang/invoke/BoundMethodHandle$Species_LL)\n\tat java.base/java.lang.invoke.BoundMethodHandle$Species_LL.make(java/lang/invoke/BoundMethodHandle$Species_LL)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.BoundMethodHandle$Species_L.copyWithExtendL(BoundMethodHandle.java:236)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvertByEditor(MethodHandleImpl.java:333)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvert(MethodHandleImpl.java:265)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvert(MethodHandleImpl.java:382)\n\tat java.base/java.lang.invoke.MethodHandle.asTypeUncached(MethodHandle.java:905)\n\tat java.base/java.lang.invoke.MethodHandle.asType(MethodHandle.java:870)\n\tat java.base/jdk.internal.reflect.MethodHandleAccessorFactory.newConstructorAccessor(MethodHandleAccessorFactory.java:114)\n\tat java.base/jdk.internal.reflect.ReflectionFactory.newConstructorAccessor(ReflectionFactory.java:200)\n\tat java.base/java.lang.reflect.Constructor.acquireConstructorAccessor(Constructor.java:549)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:193)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.lang.Object.clone(Native Method)\n\tat java.base/java.lang.invoke.LambdaForm.create(LambdaForm.java:337)\n\tat java.base/java.lang.invoke.LambdaForm.create(LambdaForm.java:369)\n\tat java.base/java.lang.invoke.DelegatingMethodHandle.makeReinvokerForm(DelegatingMethodHandle.java:162)\n\tat java.base/java.lang.invoke.DelegatingMethodHandle.makeReinvokerForm(DelegatingMethodHandle.java:120)\n\tat java.base/java.lang.invoke.BoundMethodHandle.makeReinvoker(BoundMethodHandle.java:111)\n\tat java.base/java.lang.invoke.DirectMethodHandle.rebind(DirectMethodHandle.java:148)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvertByEditor(MethodHandleImpl.java:289)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvert(MethodHandleImpl.java:265)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvert(MethodHandleImpl.java:382)\n\tat java.base/java.lang.invoke.MethodHandle.asTypeUncached(MethodHandle.java:905)\n\tat java.base/java.lang.invoke.MethodHandle.asType(MethodHandle.java:870)\n\tat java.base/jdk.internal.reflect.MethodHandleAccessorFactory.newConstructorAccessor(MethodHandleAccessorFactory.java:114)\n\tat java.base/jdk.internal.reflect.ReflectionFactory.newConstructorAccessor(ReflectionFactory.java:200)\n\tat java.base/java.lang.reflect.Constructor.acquireConstructorAccessor(Constructor.java:549)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:193)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:667)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.pollPool(JvmScheduler.scala:103)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.postschedule(JvmScheduler.scala:150)\n\tat io.reactors.JvmScheduler$Executed.postschedule(JvmScheduler.scala:273)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:202)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.util.ArrayList.grow(ArrayList.java:239)\n\tat java.base/java.util.ArrayList.grow(ArrayList.java:244)\n\tat java.base/java.util.ArrayList.add(ArrayList.java:483)\n\tat java.base/java.util.ArrayList.add(ArrayList.java:496)\n\tat java.base/java.lang.invoke.LambdaFormBuffer.noteDuplicate(LambdaFormBuffer.java:194)\n\tat java.base/java.lang.invoke.LambdaFormBuffer.replaceParameterByCopy(LambdaFormBuffer.java:373)\n\tat java.base/java.lang.invoke.LambdaFormEditor.makeArgumentCombinationForm(LambdaFormEditor.java:864)\n\tat java.base/java.lang.invoke.LambdaFormEditor.filterArgumentForm(LambdaFormEditor.java:714)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvertByEditor(MethodHandleImpl.java:331)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvert(MethodHandleImpl.java:265)\n\tat java.base/java.lang.invoke.MethodHandleImpl.makePairwiseConvert(MethodHandleImpl.java:382)\n\tat java.base/java.lang.invoke.MethodHandle.asTypeUncached(MethodHandle.java:905)\n\tat java.base/java.lang.invoke.MethodHandle.asType(MethodHandle.java:870)\n\tat java.base/jdk.internal.reflect.MethodHandleAccessorFactory.newConstructorAccessor(MethodHandleAccessorFactory.java:114)\n\tat java.base/jdk.internal.reflect.ReflectionFactory.newConstructorAccessor(ReflectionFactory.java:200)\n\tat java.base/java.lang.reflect.Constructor.acquireConstructorAccessor(Constructor.java:549)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:193)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:667)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.pollPool(JvmScheduler.scala:103)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.postschedule(JvmScheduler.scala:150)\n\tat io.reactors.JvmScheduler$Executed.postschedule(JvmScheduler.scala:273)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:202)\njava.lang.OutOfMemoryError: GC overhead limit exceeded\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n[2024-09-23T14:07:28.649+0100] org.renaissance.core (org.renaissance.core.Launcher main)\nSEVERE: Harness failed with java.lang.NoClassDefFoundError: Could not initialize class scala.Console$\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:201)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\nCaused by: java.lang.ExceptionInInitializerError: Exception java.lang.OutOfMemoryError: GC overhead limit exceeded [in thread \"main\"]\n\nHarness failed with \n[2024-09-23T14:07:28.649+0100] org.renaissance.core (org.renaissance.core.Launcher main)\nSEVERE: Harness failed with java.lang.NoClassDefFoundError: Could not initialize class scala.Console$\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:201)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\nCaused by: java.lang.ExceptionInInitializerError: Exception java.lang.OutOfMemoryError: GC overhead limit exceeded [in thread \"main\"]\n\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\njava.lang.OutOfMemoryError: Java heap space\n\tat io.reactors.Platform$Reflect$.matchingConstructor(Platform.scala:223)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:191)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\nException in thread \"reactors-io-scheduler-reanimator\" java.lang.NullPointerException: Cannot invoke \"java.lang.Thread$UncaughtExceptionHandler.uncaughtException(java.lang.Thread, java.lang.Throwable)\" because the return value of \"io.reactors.JvmScheduler$ReactorForkJoinPool.getUncaughtExceptionHandler()\" is null\n\tat io.reactors.JvmScheduler$ReactorForkJoinReanimatorThread.run(JvmScheduler.scala:51)\njava.lang.OutOfMemoryError: Java heap space\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:74)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:193)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:667)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.pollPool(JvmScheduler.scala:103)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.postschedule(JvmScheduler.scala:150)\n\tat io.reactors.JvmScheduler$Executed.postschedule(JvmScheduler.scala:273)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:202)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-7\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-3\"\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-4\" java.lang.OutOfMemoryError: Java heap space\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-8\" java.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-6\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-11\"\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-10\" \nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-14\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-5\"\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-13\" java.lang.OutOfMemoryError: Java heap space\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-12\" java.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\nBenchmark 'reactors' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n"
                ]
            ]
        },
        "1024": {
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\norg.neo4j.graphdb.TransientTransactionFailureException: Unable to complete transaction.: The memory pool limit was exceeded. The corresponding setting can be found in the error message\n\tat org.neo4j.kernel.impl.coreapi.DefaultTransactionExceptionMapper.mapException(DefaultTransactionExceptionMapper.java:52)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:337)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\nCaused by: org.neo4j.memory.MemoryLimitExceededException: The allocation of an extra 2.0 MiB would use more than the limit 716.8 MiB. Currently using 716.0 MiB. dbms.memory.transaction.total.max threshold reached\n\tat org.neo4j.memory.MemoryPoolImpl.reserveMemory(MemoryPoolImpl.java:90)\n\tat org.neo4j.memory.MemoryPoolImpl.reserveHeap(MemoryPoolImpl.java:74)\n\tat org.neo4j.memory.DelegatingMemoryPool.reserveHeap(DelegatingMemoryPool.java:31)\n\tat org.neo4j.memory.DatabaseMemoryGroupTracker.reserveHeap(DatabaseMemoryGroupTracker.java:65)\n\tat org.neo4j.kernel.impl.api.TransactionMemoryPool.reserveHeap(TransactionMemoryPool.java:90)\n\tat org.neo4j.memory.LocalMemoryTracker.reserveHeapFromPool(LocalMemoryTracker.java:264)\n\tat org.neo4j.memory.LocalMemoryTracker.allocateHeap(LocalMemoryTracker.java:183)\n\tat org.neo4j.internal.recordstorage.Loaders$2.copy(Loaders.java:207)\n\tat org.neo4j.internal.recordstorage.Loaders$2.copy(Loaders.java:181)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.ensureHasBeforeRecordImage(RecordChanges.java:217)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.prepareForChange(RecordChanges.java:170)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.forChangingData(RecordChanges.java:166)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:137)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\t... 18 more\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.neo4j.kernel.impl.store.LongerShortString.encode(LongerShortString.java:89)\n\tat org.neo4j.kernel.impl.store.PropertyStore$PropertyBlockValueWriter.writeString(PropertyStore.java:497)\n\tat org.neo4j.values.storable.ValueWriter.writeUTF8(ValueWriter.java:77)\n\tat org.neo4j.values.storable.UTF8StringValue.writeTo(UTF8StringValue.java:60)\n\tat org.neo4j.kernel.impl.store.PropertyStore.encodeValue(PropertyStore.java:364)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.encodePropertyValue(PropertyCreator.java:189)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:63)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl$$Lambda/0x00007b0c0c73b9a0.perform(Unknown Source)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007b0c0c11bbe0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nException in thread \"neo4j.Scheduler-1\" java.lang.OutOfMemoryError: Java heap space\n\tat java.base/jdk.internal.misc.Unsafe.allocateInstance(Native Method)\n\tat java.base/java.lang.invoke.DirectMethodHandle.allocateInstance(DirectMethodHandle.java:501)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.newInvokeSpecial(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n\tat org.neo4j.kernel.impl.scheduler.ThreadPoolManager.getThreadPool(ThreadPoolManager.java:56)\n\tat org.neo4j.kernel.impl.scheduler.ThreadPoolManager.getThreadPool(ThreadPoolManager.java:52)\n\tat org.neo4j.kernel.impl.scheduler.ScheduledJobHandle.submitIfRunnable(ScheduledJobHandle.java:148)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.scheduleDueTasks(TimeBasedTaskScheduler.java:146)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.tick(TimeBasedTaskScheduler.java:129)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.run(TimeBasedTaskScheduler.java:119)\n\tat java.base/java.lang.Thread.runWith(Thread.java:1596)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"neo4j.VmPauseMonitor-1\"\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n"
                ]
            ],
            "h2": [
                [
                    "Z",
                    "Error code not found: 255\n===== DaCapo 23.11-chopin h2 starting warmup 1 =====\nStarting 100000 requests...\nCompleted requests\n===== DaCapo 23.11-chopin h2 completed warmup 1 in 159454 msec =====\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.dacapo.harness.LatencyReporter.reportLatency(LatencyReporter.java:146)\n\tat org.dacapo.harness.Benchmark.postIteration(Benchmark.java:730)\n\tat org.dacapo.harness.H2.postIteration(H2.java:118)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:264)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00000000800c1000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00000000800c2c00.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 2 more\n"
                ]
            ]
        }
    }
}