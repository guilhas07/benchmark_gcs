{
    "jdk": "HotSpot_21.0.4",
    "failed_benchmarks": {
        "256": {
            "page-rank": [
                [
                    "G1",
                    "Error code not found: 1\n01:27:29.194 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:37:24.721 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\n03:46:58.053 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n05:18:23.489 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "movie-lens": [
                [
                    "G1",
                    "Error code not found: 1\n01:30:12.031 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:38:21.448 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\n04:02:23.359 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n05:18:59.562 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "chi-square": [
                [
                    "G1",
                    "Error code not found: 1\n01:30:35.159 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:38:44.513 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\n04:02:46.523 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n05:19:37.710 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.mutable.ListBuffer.addOne(ListBuffer.scala:116)\n\tat scala.collection.mutable.ListBuffer.addOne(ListBuffer.scala:39)\n\tat scala.collection.mutable.Growable.$plus$eq(Growable.scala:36)\n\tat scala.collection.mutable.Growable.$plus$eq$(Growable.scala:36)\n\tat scala.collection.mutable.AbstractBuffer.$plus$eq(Buffer.scala:232)\n\tat play.api.libs.json.jackson.KeyRead.addValue(JacksonJson.scala:143)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:244)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:101)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007f397011c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007f3970004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007f397000a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:202)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:101)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000079d88811c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x000079d888004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000079d88800a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.lang.StringUTF16.compress(StringUTF16.java:161)\n\tat java.base/java.lang.String.<init>(String.java:4768)\n\tat java.base/java.lang.String.<init>(String.java:303)\n\tat com.fasterxml.jackson.core.util.TextBuffer.contentsAsString(TextBuffer.java:468)\n\tat com.fasterxml.jackson.core.json.ReaderBasedJsonParser.getText(ReaderBasedJsonParser.java:325)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:202)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:101)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007542f011c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007542f0004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007542f000a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat play.api.libs.json.jackson.ReadingMap.setField(JacksonJson.scala:148)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:222)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:101)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007a68cc11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007a68cc004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007a68cc00a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "reactors": [
                [
                    "G1",
                    "Error code not found: 1\nException in thread \"reactors-io-scheduler-reanimator\" java.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:74)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:193)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:667)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.pollPool(JvmScheduler.scala:103)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.postschedule(JvmScheduler.scala:150)\n\tat io.reactors.JvmScheduler$Executed.postschedule(JvmScheduler.scala:273)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:202)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.base/jdk.internal.org.objectweb.asm.ByteVector.enlarge(ByteVector.java:401)\n\tat java.base/jdk.internal.org.objectweb.asm.ByteVector.putUTF8(ByteVector.java:291)\n\tat java.base/jdk.internal.org.objectweb.asm.SymbolTable.addConstantUtf8(SymbolTable.java:806)\n\tat java.base/jdk.internal.org.objectweb.asm.SymbolTable.addConstantNameAndType(SymbolTable.java:772)\n\tat java.base/jdk.internal.org.objectweb.asm.SymbolTable.addConstantMemberReference(SymbolTable.java:604)\n\tat java.base/jdk.internal.org.objectweb.asm.SymbolTable.addConstantFieldref(SymbolTable.java:558)\n\tat java.base/jdk.internal.org.objectweb.asm.MethodWriter.visitFieldInsn(MethodWriter.java:1027)\n\tat java.base/java.lang.invoke.InvokerBytecodeGenerator.emitStaticInvoke(InvokerBytecodeGenerator.java:1055)\n\tat java.base/java.lang.invoke.InvokerBytecodeGenerator.addMethod(InvokerBytecodeGenerator.java:861)\n\tat java.base/java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCodeBytes(InvokerBytecodeGenerator.java:754)\n\tat java.base/java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCode(InvokerBytecodeGenerator.java:712)\n\tat java.base/java.lang.invoke.LambdaForm.compileToBytecode(LambdaForm.java:849)\n\tat java.base/java.lang.invoke.LambdaForm.customize(LambdaForm.java:468)\n\tat java.base/java.lang.invoke.MethodHandle$1.apply(MethodHandle.java:1858)\n\tat java.base/java.lang.invoke.MethodHandle$1.apply(MethodHandle.java:1856)\n\tat java.base/java.lang.invoke.MethodHandle.updateForm(MethodHandle.java:1878)\n\tat java.base/java.lang.invoke.MethodHandle.customize(MethodHandle.java:1856)\n\tat java.base/java.lang.invoke.MethodHandle.maybeCustomize(MethodHandle.java:1846)\n\tat java.base/java.lang.invoke.Invokers.maybeCustomize(Invokers.java:633)\n\tat java.base/java.lang.invoke.Invokers.checkCustomized(Invokers.java:627)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.invokeImpl(DirectConstructorHandleAccessor.java:87)\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:193)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.lang.reflect.Array.newInstance(Array.java:78)\n\tat scala.reflect.ClassTag$GenericClassTag.newArray(ClassTag.scala:171)\n\tat scala.collection.mutable.ArrayBuilder$ofRef.mkArray(ArrayBuilder.scala:74)\n\tat scala.collection.mutable.ArrayBuilder$ofRef.resize(ArrayBuilder.scala:79)\n\tat scala.collection.mutable.ArrayBuilder$ofRef.ensureSize(ArrayBuilder.scala:91)\n\tat scala.collection.mutable.ArrayBuilder$ofRef.$plus$eq(ArrayBuilder.scala:96)\n\tat scala.collection.mutable.ArrayBuilder$ofRef.$plus$eq(ArrayBuilder.scala:66)\n\tat scala.collection.TraversableLike.$anonfun$filterImpl$1(TraversableLike.scala:304)\n\tat scala.collection.TraversableLike$$Lambda/0x000072a12c203410.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n\tat scala.collection.TraversableLike.filterImpl(TraversableLike.scala:303)\n\tat scala.collection.TraversableLike.filterImpl$(TraversableLike.scala:297)\n\tat scala.collection.mutable.ArrayOps$ofRef.filterImpl(ArrayOps.scala:198)\n\tat scala.collection.TraversableLike.filter(TraversableLike.scala:395)\n\tat scala.collection.TraversableLike.filter$(TraversableLike.scala:395)\n\tat scala.collection.mutable.ArrayOps$ofRef.filter(ArrayOps.scala:198)\n\tat io.reactors.Platform$Reflect$.matchingConstructor(Platform.scala:223)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:191)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:667)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.pollPool(JvmScheduler.scala:103)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.postschedule(JvmScheduler.scala:150)\n\tat io.reactors.JvmScheduler$Executed.postschedule(JvmScheduler.scala:273)\njava.lang.NullPointerException: Cannot invoke \"java.lang.Thread$UncaughtExceptionHandler.uncaughtException(java.lang.Thread, java.lang.Throwable)\" because the return value of \"io.reactors.JvmScheduler$ReactorForkJoinPool.getUncaughtExceptionHandler()\" is null\n\tat io.reactors.JvmScheduler$ReactorForkJoinReanimatorThread.run(JvmScheduler.scala:51)\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:74)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:193)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:667)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.pollPool(JvmScheduler.scala:103)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.postschedule(JvmScheduler.scala:150)\n\tat io.reactors.JvmScheduler$Executed.postschedule(JvmScheduler.scala:273)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:202)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat io.reactors.Events$Push.onReaction(Events.scala:1230)\n\tat io.reactors.Events$Push.onReaction$(Events.scala:1223)\n\tat io.reactors.Events$Emitter.onReaction(Events.scala:1489)\n\tat io.reactors.Events.on(Events.scala:153)\n\tat io.reactors.Events.on$(Events.scala:152)\n\tat io.reactors.Events$Emitter.on(Events.scala:1489)\n\tat org.renaissance.actors.ForkJoinCreation$.$anonfun$run$18(Reactors.scala:315)\n\tat org.renaissance.actors.ForkJoinCreation$.$anonfun$run$18$adapted(Reactors.scala:314)\n\tat org.renaissance.actors.ForkJoinCreation$$$Lambda/0x000072a12c287ae8.apply(Unknown Source)\n\tat io.reactors.concurrent.AnonymousReactor.<init>(package.scala:11)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.newInvokeSpecial(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000072a12c009400.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.invokeImpl(DirectConstructorHandleAccessor.java:87)\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n\tat io.reactors.Platform$Reflect$.instantiate(Platform.scala:193)\n\tat io.reactors.Proto.create(Proto.scala:25)\n\tat io.reactors.concurrent.Frame.checkFresh(Frame.scala:237)\n\tat io.reactors.concurrent.Frame.processBatch(Frame.scala:491)\n\tat io.reactors.concurrent.Frame.isolateAndProcessBatch(Frame.scala:210)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:183)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\n\tat java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1423)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:667)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.pollPool(JvmScheduler.scala:103)\n\tat io.reactors.JvmScheduler$ReactorForkJoinWorkerThread.postschedule(JvmScheduler.scala:150)\n\tat io.reactors.JvmScheduler$Executed.postschedule(JvmScheduler.scala:273)\n\tat io.reactors.concurrent.Frame.executeBatch(Frame.scala:202)\n\tat io.reactors.JvmScheduler$Executed$$anon$5.run(JvmScheduler.scala:255)\nBenchmark 'reactors' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nFailed to load benchmark 'reactors': GC overhead limit exceeded\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\nException in thread \"reactors-io-scheduler-reanimator\" java.lang.OutOfMemoryError: Java heap space\n\tat io.reactors.JvmScheduler$ReactorForkJoinReanimatorThread.run(JvmScheduler.scala:51)\nBenchmark 'reactors' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.lang.reflect.Array.newInstance(Array.java:78)\n\tat scala.reflect.ClassTag$GenericClassTag.newArray(ClassTag.scala:171)\n\tat io.reactors.Arrayable$$anon$2.newArray(Arrayable.scala:94)\n\tat io.reactors.Arrayable$$anon$2.newRawArray(Arrayable.scala:95)\n\tat io.reactors.Arrayable$$anon$2.newRawArray(Arrayable.scala:91)\n\tat io.reactors.common.UnrolledRing.init(UnrolledRing.scala:21)\n\tat io.reactors.common.UnrolledRing.<init>(UnrolledRing.scala:27)\n\tat io.reactors.EventQueue$UnrolledRing.<init>(EventQueue.scala:95)\n\tat io.reactors.EventQueue$UnrolledRing$Factory$.newInstance(EventQueue.scala:142)\n\tat io.reactors.concurrent.Frame.openConnector(Frame.scala:90)\n\tat io.reactors.ReactorSystem.trySpawnReactor(ReactorSystem.scala:148)\n\tat io.reactors.ReactorSystem.spawn(ReactorSystem.scala:91)\n\tat org.renaissance.actors.ForkJoinCreation$.$anonfun$run$17(Reactors.scala:314)\n\tat org.renaissance.actors.ForkJoinCreation$.$anonfun$run$17$adapted(Reactors.scala:313)\n\tat org.renaissance.actors.ForkJoinCreation$$$Lambda/0x00007483e8287348.apply(Unknown Source)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n\tat scala.collection.TraversableLike$$Lambda/0x00007483e81ceef0.apply(Unknown Source)\n\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n\tat org.renaissance.actors.ForkJoinCreation$.run(Reactors.scala:313)\n\tat org.renaissance.actors.Reactors.run(Reactors.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeOperation(ExecutionDriver.java:137)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:93)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007483e811c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-reanimator\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-8\"\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-1\" Exception in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-5\" java.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\nFailed to load benchmark 'reactors': Java heap space\n"
                ]
            ],
            "dec-tree": [
                [
                    "G1",
                    "Error code not found: 1\n01:32:15.582 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:40:19.232 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\n04:04:52.291 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n05:23:26.254 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "naive-bayes": [
                [
                    "G1",
                    "Error code not found: 1\n01:32:35.482 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:41:29.586 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\n04:05:29.559 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n05:23:37.620 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "als": [
                [
                    "G1",
                    "Error code not found: 1\n01:32:38.702 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:41:32.935 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\n04:05:32.897 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n05:23:40.871 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "log-regression": [
                [
                    "G1",
                    "Error code not found: 1\n01:33:26.959 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:42:18.061 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\n04:06:25.832 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n05:24:36.448 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "gauss-mix": [
                [
                    "G1",
                    "Error code not found: 1\n01:33:30.399 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:42:21.440 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\n04:06:29.061 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 259522560 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n05:24:39.743 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "akka-uct": [
                [
                    "Parallel",
                    "Error code not found: 255\nUncaught error from thread [Uncaught error from thread [Uncaught error from thread [UCT-akka.actor.default-dispatcher-11Uncaught error from thread [UCT-akka.actor.default-dispatcher-19]: Uncaught error from thread [UCT-akka.actor.default-dispatcher-15]: GC overhead limit exceededUncaught error from thread [UCT-akka.actor.default-dispatcher-19]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\nUncaught error from thread [UCT-akka.actor.default-dispatcher-20]: GC overhead limit exceeded, UCT-akka.actor.default-dispatcher-9]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat scala.collection.immutable.List.prependedAll(List.scala:156)\n\tat scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)\n\tat scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)\n\tat scala.collection.AbstractIterable.toList(Iterable.scala:933)\n\tat akka.actor.Props$.apply(Props.scala:86)\n\tat akka.actor.Props$.mkProps(Props.scala:81)\n\tat akka.actor.Props$.apply(Props.scala:78)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateUrgentChildren(UctAkkaActorBenchmark.scala:323)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:249)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\nUCT-akka.actor.default-dispatcher-8]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.lang.invoke.DirectMethodHandle.allocateInstance(DirectMethodHandle.java:501)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x000072bbcc2b0800.newInvokeSpecial(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000072bbcc2b1000.linkToTargetMethod(LambdaForm$MH)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\n]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat scala.collection.immutable.RedBlackTree$Tree.withRight(RedBlackTree.scala:690)\n\tat scala.collection.immutable.RedBlackTree$.balanceRight(RedBlackTree.scala:403)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.update(RedBlackTree.scala:175)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.add(ChildrenContainer.scala:113)\n\tat akka.actor.dungeon.Children.initChild(Children.scala:161)\n\tat akka.actor.dungeon.Children.initChild$(Children.scala:22)\n\tat akka.actor.ActorCell.initChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:324)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\nGC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat scala.collection.immutable.RedBlackTree$Tree.withV(RedBlackTree.scala:672)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:412)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.update(RedBlackTree.scala:175)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.add(ChildrenContainer.scala:113)\n\tat akka.actor.dungeon.Children.initChild(Children.scala:161)\n\tat akka.actor.dungeon.Children.initChild$(Children.scala:22)\n\tat akka.actor.ActorCell.initChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:324)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nshutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-18]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-12]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.internal-dispatcher-2]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-14]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-6]: Could not initialize class scala.PartialFunction$, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.NoClassDefFoundError: Could not initialize class scala.PartialFunction$\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:552)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\nCaused by: java.lang.ExceptionInInitializerError: Exception java.lang.OutOfMemoryError: GC overhead limit exceeded [in thread \"UCT-akka.actor.default-dispatcher-14\"]\n"
                ],
                [
                    "Z",
                    "Error code not found: 255\nUncaught error from thread [UCT-akka.actor.internal-dispatcher-3]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nUncaught error from thread [UCT-akka.actor.default-dispatcher-17]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCTUncaught error from thread [UCT-akka.actor.default-dispatcher-19]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nUncaught error from thread [Uncaught error from thread [UCT-akka.actor.default-dispatcher-8]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\n]\njava.lang.OutOfMemoryError: Java heap space\nUncaught error from thread [Uncaught error from thread [UCT-akka.actor.default-dispatcher-6]: Runtime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nUncaught error from thread [UCT-akka.actor.default-dispatcher-18]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nUncaught error from thread [UCT-akka.actor.default-dispatcher-15]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nUncaught error from thread [UCT-akka.actor.default-dispatcher-13]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nUncaught error from thread [UCT-akka.actor.default-dispatcher-4]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nUncaught error from thread [UCT-akka.actor.default-dispatcher-12]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nUncaught error from thread [Runtime.exit(-1) logging failed: Java heap space\nUCT-akka.actor.default-dispatcher-9]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nJava heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nUncaught error from thread [UCT-akka.actor.default-dispatcher-16]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\nRuntime.exit(-1) logging failed: Could not initialize class jdk.internal.logger.LazyLoggers\n"
                ]
            ],
            "scala-stm-bench7": [
                [
                    "Parallel",
                    "Error code not found: 1\nSetup start...\nSetting up the design library:\nException in thread \"Thread-2\" java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.util.jar.Manifest$FastInputStream.<init>(Manifest.java:421)\n\tat java.base/java.util.jar.Manifest$FastInputStream.<init>(Manifest.java:416)\n\tat java.base/java.util.jar.Manifest.read(Manifest.java:287)\n\tat java.base/java.util.jar.Manifest.<init>(Manifest.java:101)\n\tat java.base/java.util.jar.Manifest.<init>(Manifest.java:88)\n\tat java.base/java.util.jar.JarFile.getManifestFromReference(JarFile.java:431)\n\tat java.base/java.util.jar.JarFile.getManifest(JarFile.java:405)\n\tat java.base/jdk.internal.loader.URLClassPath$JarLoader$2.getManifest(URLClassPath.java:853)\n\tat java.base/java.net.URLClassLoader.defineClass(URLClassLoader.java:491)\n\tat java.base/java.net.URLClassLoader$1.run(URLClassLoader.java:427)\n\tat java.base/java.net.URLClassLoader$1.run(URLClassLoader.java:421)\n\tat java.base/java.security.AccessController.executePrivileged(AccessController.java:809)\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Thread-2\"\nException in thread \"main\" java.lang.OutOfMemoryError: GC overhead limit exceeded\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nSetup start...\nSetting up the design library:\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Thread-2\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\"\n"
                ]
            ]
        },
        "512": {
            "page-rank": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.io.BufferedReader.implReadLine(BufferedReader.java:403)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:347)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:436)\n\tat scala.io.BufferedSource$BufferedLineIterator.hasNext(BufferedSource.scala:73)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:653)\n\tat scala.collection.immutable.List.prependedAll(List.scala:155)\n\tat scala.collection.immutable.List$.from(List.scala:684)\n\tat scala.collection.immutable.List$.from(List.scala:681)\n\tat scala.collection.SeqFactory$Delegate.from(Factory.scala:306)\n\tat scala.collection.immutable.Seq$.from(Seq.scala:42)\n\tat scala.collection.IterableOnceOps.toSeq(IterableOnce.scala:1326)\n\tat scala.collection.IterableOnceOps.toSeq$(IterableOnce.scala:1326)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1300)\n\tat org.renaissance.apache.spark.PageRank.copyLinesToFile(PageRank.scala:87)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:114)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x0000730cc411c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000730cc4004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000730cc400a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n02:47:36.683 WARN  [dispatcher-HeartbeatReceiver] org.apache.spark.HeartbeatReceiver - Removing executor driver with no recent heartbeats: 134141 ms exceeds timeout 120000 ms\n02:47:36.689 WARN  [kill-executor-thread] org.apache.spark.SparkContext - Killing executors is not supported by current scheduler.\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.List.prependedAll(List.scala:156)\n\tat scala.collection.immutable.List$.from(List.scala:684)\n\tat scala.collection.immutable.List$.from(List.scala:681)\n\tat scala.collection.SeqFactory$Delegate.from(Factory.scala:306)\n\tat scala.collection.immutable.Seq$.from(Seq.scala:42)\n\tat scala.collection.IterableOnceOps.toSeq(IterableOnce.scala:1326)\n\tat scala.collection.IterableOnceOps.toSeq$(IterableOnce.scala:1326)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1300)\n\tat org.renaissance.apache.spark.PageRank.copyLinesToFile(PageRank.scala:87)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:114)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000071537c11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x000071537c004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000071537c00a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.io.BufferedReader.implReadLine(BufferedReader.java:403)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:347)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:436)\n\tat scala.io.BufferedSource$BufferedLineIterator.hasNext(BufferedSource.scala:73)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:653)\n\tat scala.collection.immutable.List.prependedAll(List.scala:155)\n\tat scala.collection.immutable.List$.from(List.scala:684)\n\tat scala.collection.immutable.List$.from(List.scala:681)\n\tat scala.collection.SeqFactory$Delegate.from(Factory.scala:306)\n\tat scala.collection.immutable.Seq$.from(Seq.scala:42)\n\tat scala.collection.IterableOnceOps.toSeq(IterableOnce.scala:1326)\n\tat scala.collection.IterableOnceOps.toSeq$(IterableOnce.scala:1326)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1300)\n\tat org.renaissance.apache.spark.PageRank.copyLinesToFile(PageRank.scala:87)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:114)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007269dc11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007269dc004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007269dc00a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.List.prependedAll(List.scala:156)\n\tat scala.collection.immutable.List$.from(List.scala:684)\n\tat scala.collection.immutable.List$.from(List.scala:681)\n\tat scala.collection.SeqFactory$Delegate.from(Factory.scala:306)\n\tat scala.collection.immutable.Seq$.from(Seq.scala:42)\n\tat scala.collection.IterableOnceOps.toSeq(IterableOnce.scala:1326)\n\tat scala.collection.IterableOnceOps.toSeq$(IterableOnce.scala:1326)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1300)\n\tat org.renaissance.apache.spark.PageRank.copyLinesToFile(PageRank.scala:87)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:114)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007a745411c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007a7454004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007a745400a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.allocateTable(LongObjectHashMap.java:3022)\n\tat org.neo4j.collection.trackable.HeapTrackingLongObjectHashMap.allocateTable(HeapTrackingLongObjectHashMap.java:62)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehash(LongObjectHashMap.java:2908)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehashAndGrow(LongObjectHashMap.java:2900)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.addKeyValueAtIndex(LongObjectHashMap.java:2742)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.getIfAbsentPut(LongObjectHashMap.java:2357)\n\tat org.neo4j.kernel.impl.api.state.TxState.getOrCreateNodeState(TxState.java:673)\n\tat org.neo4j.kernel.impl.api.state.TxState.getOrCreateNodeStateLabelDiffSets(TxState.java:337)\n\tat org.neo4j.kernel.impl.api.state.TxState.nodeDoAddLabel(TxState.java:499)\n\tat org.neo4j.kernel.impl.newapi.Operations.checkConstraintsAndAddLabelToNode(Operations.java:420)\n\tat org.neo4j.kernel.impl.newapi.Operations.nodeCreateWithLabels(Operations.java:276)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.createNode(TransactionImpl.java:208)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.$anonfun$populateVertices$1(AnalyticsBenchmark.scala:73)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.$anonfun$populateVertices$1$adapted(AnalyticsBenchmark.scala:72)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark$$Lambda/0x0000761a00899c08.apply(Unknown Source)\n\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)\n\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:933)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:72)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x0000761a0011c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000761a00004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000761a0000a000.invoke(LambdaForm$MH)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.lang.StringLatin1.toChars(StringLatin1.java:71)\n\tat java.base/java.lang.String.toCharArray(String.java:4348)\n\tat java.base/java.math.BigDecimal.<init>(BigDecimal.java:919)\n\tat play.api.libs.json.BigDecimalParser$.parse(BigDecimalParser.scala:19)\n\tat play.api.libs.json.jackson.JsValueDeserializer.parseBigDecimal(JacksonJson.scala:170)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:200)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:102)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007dbdcf11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007dbdcf004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007dbdcf00a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.allocateTable(LongObjectHashMap.java:3021)\n\tat org.neo4j.collection.trackable.HeapTrackingLongObjectHashMap.allocateTable(HeapTrackingLongObjectHashMap.java:62)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehash(LongObjectHashMap.java:2908)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehashAndGrow(LongObjectHashMap.java:2900)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.addKeyValueAtIndex(LongObjectHashMap.java:2742)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.getIfAbsentPut(LongObjectHashMap.java:2357)\n\tat org.neo4j.kernel.impl.api.state.TxState.getOrCreateNodeState(TxState.java:673)\n\tat org.neo4j.kernel.impl.api.state.TxState.getOrCreateNodeStateLabelDiffSets(TxState.java:337)\n\tat org.neo4j.kernel.impl.api.state.TxState.nodeDoAddLabel(TxState.java:499)\n\tat org.neo4j.kernel.impl.newapi.Operations.checkConstraintsAndAddLabelToNode(Operations.java:420)\n\tat org.neo4j.kernel.impl.newapi.Operations.nodeCreateWithLabels(Operations.java:276)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.createNode(TransactionImpl.java:208)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.$anonfun$populateVertices$1(AnalyticsBenchmark.scala:73)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.$anonfun$populateVertices$1$adapted(AnalyticsBenchmark.scala:72)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark$$Lambda/0x000072d7cc89f468.apply(Unknown Source)\n\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)\n\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:933)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:72)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000072d7cc11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x000072d7cc004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000072d7cc00a000.invoke(LambdaForm$MH)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.mutable.ListBuffer$.from(ListBuffer.scala:399)\n\tat scala.collection.mutable.ListBuffer$.from(ListBuffer.scala:397)\n\tat scala.collection.IterableFactory.apply(Factory.scala:103)\n\tat scala.collection.IterableFactory.apply$(Factory.scala:103)\n\tat scala.collection.mutable.ListBuffer$.apply(ListBuffer.scala:397)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:218)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:102)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007fa60c11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007fa60c004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007fa60c00a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n"
                ]
            ],
            "naive-bayes": [
                [
                    "G1",
                    "Error code not found: 52\n01:43:10.517 WARN  [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.storage.BlockManager - Block rdd_3_3 could not be removed as it was not found on disk or in memory\n01:43:10.668 ERROR [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.executor.Executor - Exception in task 3.0 in stage 0.0 (TID 3)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.lang.StringLatin1.newString(StringLatin1.java:752) ~[?:?]\n\tat java.lang.String.substring(String.java:2839) ~[?:?]\n\tat java.lang.String.split(String.java:3371) ~[?:?]\n\tat java.lang.String.split(String.java:3354) ~[?:?]\n\tat java.lang.String.split(String.java:3447) ~[?:?]\n\tat scala.collection.StringOps$.split$extension(StringOps.scala:836) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.mllib.util.MLUtils$.parseLibSVMRecord(MLUtils.scala:130) ~[spark-mllib_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.ml.source.libsvm.LibSVMFileFormat.$anonfun$buildReader$6(LibSVMRelation.scala:166) ~[spark-mllib_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.ml.source.libsvm.LibSVMFileFormat$$Lambda/0x00007948ccd20f00.apply(Unknown Source) ~[?:?]\n\tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584) ~[scala-library-2.13.12.jar:?]\n\tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584) ~[scala-library-2.13.12.jar:?]\n\tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.next(FileScanRDD.scala:197) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007948ccb2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n01:43:10.814 ERROR [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#84,Executor task launch worker for task 3.0 in stage 0.0 (TID 3),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.lang.StringLatin1.newString(StringLatin1.java:752) ~[?:?]\n\tat java.lang.String.substring(String.java:2839) ~[?:?]\n\tat java.lang.String.split(String.java:3371) ~[?:?]\n\tat java.lang.String.split(String.java:3354) ~[?:?]\n\tat java.lang.String.split(String.java:3447) ~[?:?]\n\tat scala.collection.StringOps$.split$extension(StringOps.scala:836) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.mllib.util.MLUtils$.parseLibSVMRecord(MLUtils.scala:130) ~[spark-mllib_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.ml.source.libsvm.LibSVMFileFormat.$anonfun$buildReader$6(LibSVMRelation.scala:166) ~[spark-mllib_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.ml.source.libsvm.LibSVMFileFormat$$Lambda/0x00007948ccd20f00.apply(Unknown Source) ~[?:?]\n\tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584) ~[scala-library-2.13.12.jar:?]\n\tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584) ~[scala-library-2.13.12.jar:?]\n\tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.next(FileScanRDD.scala:197) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.collection.Iterator$$anon$9.next(Iterator.scala:584) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:90) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007948ccb2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 52\n02:53:52.212 WARN  [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] org.apache.spark.storage.BlockManager - Block rdd_3_5 could not be removed as it was not found on disk or in memory\n02:53:52.651 ERROR [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] org.apache.spark.executor.Executor - Exception in task 5.0 in stage 0.0 (TID 5)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x000077579bb2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000077579bbf37e0.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n02:53:53.393 ERROR [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#81,Executor task launch worker for task 5.0 in stage 0.0 (TID 5),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x000077579bb2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000077579bbf37e0.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n02:53:53.459 WARN  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Lost task 5.0 in stage 0.0 (TID 5) (archlinux executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71)\n\tat java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:391)\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167)\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93)\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61)\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105)\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601)\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x000077579bb2d018.apply(Unknown Source)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x000077579bbf37e0.apply(Unknown Source)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\n"
                ],
                [
                    "Serial",
                    "Error code not found: 52\n04:18:55.123 WARN  [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] org.apache.spark.storage.BlockManager - Block rdd_3_0 could not be removed as it was not found on disk or in memory\n04:18:55.239 ERROR [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007677d4b2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007677d4bf2f98.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n04:18:55.482 ERROR [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#68,Executor task launch worker for task 0.0 in stage 0.0 (TID 0),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007677d4b2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007677d4bf2f98.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n"
                ],
                [
                    "Z",
                    "Error code not found: 52\n05:41:37.342 WARN  [Executor task launch worker for task 6.0 in stage 0.0 (TID 6)] org.apache.spark.storage.BlockManager - Block rdd_3_6 could not be removed as it was not found on disk or in memory\n05:41:37.343 WARN  [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] org.apache.spark.storage.BlockManager - Block rdd_3_5 could not be removed as it was not found on disk or in memory\n05:41:37.542 ERROR [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] org.apache.spark.executor.Executor - Exception in task 5.0 in stage 0.0 (TID 5)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x0000787b44b28b10.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x0000787b44bf2640.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n05:41:37.499 ERROR [Executor task launch worker for task 6.0 in stage 0.0 (TID 6)] org.apache.spark.executor.Executor - Exception in task 6.0 in stage 0.0 (TID 6)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x0000787b44b28b10.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x0000787b44bf2640.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n05:41:37.674 ERROR [Executor task launch worker for task 6.0 in stage 0.0 (TID 6)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#86,Executor task launch worker for task 6.0 in stage 0.0 (TID 6),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x0000787b44b28b10.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x0000787b44bf2640.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n"
                ]
            ],
            "reactors": [
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'reactors' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat io.reactors.EventQueue$UnrolledRing.<init>(EventQueue.scala:95)\n\tat io.reactors.EventQueue$UnrolledRing$Factory$.newInstance(EventQueue.scala:142)\n\tat io.reactors.concurrent.Frame.openConnector(Frame.scala:90)\n\tat io.reactors.ReactorSystem.trySpawnReactor(ReactorSystem.scala:150)\n\tat io.reactors.ReactorSystem.spawn(ReactorSystem.scala:91)\n\tat org.renaissance.actors.ForkJoinCreation$.$anonfun$run$17(Reactors.scala:314)\n\tat org.renaissance.actors.ForkJoinCreation$.$anonfun$run$17$adapted(Reactors.scala:313)\n\tat org.renaissance.actors.ForkJoinCreation$$$Lambda/0x00007570a82879d8.apply(Unknown Source)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n\tat scala.collection.TraversableLike$$Lambda/0x00007570a81ceef0.apply(Unknown Source)\n\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n\tat org.renaissance.actors.ForkJoinCreation$.run(Reactors.scala:313)\n\tat org.renaissance.actors.Reactors.run(Reactors.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeOperation(ExecutionDriver.java:137)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:93)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007570a811c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007570a8004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007570a800a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nException in thread \"reactors-io-scheduler-reanimator\" Exception in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-1\" java.lang.NullPointerException: Cannot invoke \"java.lang.Thread$UncaughtExceptionHandler.uncaughtException(java.lang.Thread, java.lang.Throwable)\" because the return value of \"io.reactors.JvmScheduler$ReactorForkJoinPool.getUncaughtExceptionHandler()\" is null\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-reanimator\"\njava.lang.OutOfMemoryError: Java heap space\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-6\"\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-8\" \nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-4\"\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-3\" java.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\nBenchmark 'reactors' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n"
                ]
            ]
        },
        "1024": {
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\norg.neo4j.graphdb.TransientTransactionFailureException: Unable to complete transaction.: The memory pool limit was exceeded. The corresponding setting can be found in the error message\n\tat org.neo4j.kernel.impl.coreapi.DefaultTransactionExceptionMapper.mapException(DefaultTransactionExceptionMapper.java:52)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:337)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\nCaused by: org.neo4j.memory.MemoryLimitExceededException: The allocation of an extra 2.0 MiB would use more than the limit 716.8 MiB. Currently using 716.0 MiB. dbms.memory.transaction.total.max threshold reached\n\tat org.neo4j.memory.MemoryPoolImpl.reserveMemory(MemoryPoolImpl.java:90)\n\tat org.neo4j.memory.MemoryPoolImpl.reserveHeap(MemoryPoolImpl.java:74)\n\tat org.neo4j.memory.DelegatingMemoryPool.reserveHeap(DelegatingMemoryPool.java:31)\n\tat org.neo4j.memory.DatabaseMemoryGroupTracker.reserveHeap(DatabaseMemoryGroupTracker.java:65)\n\tat org.neo4j.kernel.impl.api.TransactionMemoryPool.reserveHeap(TransactionMemoryPool.java:90)\n\tat org.neo4j.memory.LocalMemoryTracker.reserveHeapFromPool(LocalMemoryTracker.java:264)\n\tat org.neo4j.memory.LocalMemoryTracker.allocateHeap(LocalMemoryTracker.java:183)\n\tat org.neo4j.internal.recordstorage.Loaders$2.copy(Loaders.java:207)\n\tat org.neo4j.internal.recordstorage.Loaders$2.copy(Loaders.java:181)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.ensureHasBeforeRecordImage(RecordChanges.java:217)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.prepareForChange(RecordChanges.java:170)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.forChangingData(RecordChanges.java:166)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:137)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\t... 18 more\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nException in thread \"neo4j.Scheduler-1\" \nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"neo4j.Scheduler-1\"\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.neo4j.internal.recordstorage.PropertyCreator.encodePropertyValue(PropertyCreator.java:188)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:63)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl$$Lambda/0x0000766de873b9a0.perform(Unknown Source)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x0000766de811c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000766de8004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000766de800a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n"
                ],
                [
                    "Serial",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\norg.neo4j.graphdb.TransientTransactionFailureException: Unable to complete transaction.: The memory pool limit was exceeded. The corresponding setting can be found in the error message\n\tat org.neo4j.kernel.impl.coreapi.DefaultTransactionExceptionMapper.mapException(DefaultTransactionExceptionMapper.java:52)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:337)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\nCaused by: org.neo4j.memory.MemoryLimitExceededException: The allocation of an extra 24.0 MiB would use more than the limit 692.9 MiB. Currently using 670.0 MiB. dbms.memory.transaction.total.max threshold reached\n\tat org.neo4j.memory.MemoryPoolImpl.reserveMemory(MemoryPoolImpl.java:90)\n\tat org.neo4j.memory.MemoryPoolImpl.reserveHeap(MemoryPoolImpl.java:74)\n\tat org.neo4j.memory.DelegatingMemoryPool.reserveHeap(DelegatingMemoryPool.java:31)\n\tat org.neo4j.memory.DatabaseMemoryGroupTracker.reserveHeap(DatabaseMemoryGroupTracker.java:65)\n\tat org.neo4j.kernel.impl.api.TransactionMemoryPool.reserveHeap(TransactionMemoryPool.java:90)\n\tat org.neo4j.memory.LocalMemoryTracker.reserveHeapFromPool(LocalMemoryTracker.java:264)\n\tat org.neo4j.memory.LocalMemoryTracker.allocateHeap(LocalMemoryTracker.java:183)\n\tat org.neo4j.collection.trackable.HeapTrackingLongObjectHashMap.allocateTable(HeapTrackingLongObjectHashMap.java:58)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehash(LongObjectHashMap.java:2908)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehashAndGrow(LongObjectHashMap.java:2900)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.addKeyValueAtIndex(LongObjectHashMap.java:2742)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.put(LongObjectHashMap.java:2190)\n\tat org.neo4j.internal.recordstorage.RecordChanges.create(RecordChanges.java:121)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:136)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\t... 18 more\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.allocateTable(LongObjectHashMap.java:3021)\n\tat org.neo4j.collection.trackable.HeapTrackingLongObjectHashMap.allocateTable(HeapTrackingLongObjectHashMap.java:62)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehash(LongObjectHashMap.java:2908)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehashAndGrow(LongObjectHashMap.java:2900)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.addKeyValueAtIndex(LongObjectHashMap.java:2742)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.put(LongObjectHashMap.java:2190)\n\tat org.neo4j.internal.recordstorage.RecordChanges.create(RecordChanges.java:121)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:136)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl$$Lambda/0x00007a1dec781320.perform(Unknown Source)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007a1dec11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n"
                ]
            ]
        }
    }
}