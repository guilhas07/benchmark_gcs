{
    "jdk": "HotSpot",
    "failed_benchmarks": {
        "256": {
            "h2": [
                [
                    "G1",
                    "Error code not found: 255\njava.lang.reflect.InvocationTargetException\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:237)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: org.h2.jdbc.JdbcSQLNonTransientConnectionException: Out of memory.; SQL statement:\n\n\nALTER TABLE ORDERLINE ADD CONSTRAINT\n    ORDERLINE_PK PRIMARY KEY(OL_W_ID, OL_D_ID, OL_O_ID, OL_NUMBE [90108-220]\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:690)\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:489)\n\tat org.h2.message.DbException.get(DbException.java:212)\n\tat org.h2.message.DbException.convert(DbException.java:401)\n\tat org.h2.command.Command.executeUpdate(Command.java:262)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createIndexes(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 8 more\nCaused by: java.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\n\tat org.h2.mvstore.Page$NonLeaf.setChild(Page.java:1197)\n\tat org.h2.mvstore.MVMap.replacePage(MVMap.java:1360)\n\tat org.h2.mvstore.MVMap.operate(MVMap.java:1863)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:363)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:350)\n\tat org.h2.mvstore.tx.TransactionMap.put(TransactionMap.java:265)\n\tat org.h2.mvstore.db.MVSecondaryIndex.add(MVSecondaryIndex.java:188)\n\tat org.h2.mvstore.db.MVTable.addRowsToIndex(MVTable.java:723)\n\tat org.h2.mvstore.db.MVTable.rebuildIndexBuffered(MVTable.java:467)\n\tat org.h2.mvstore.db.MVTable.rebuildIndex(MVTable.java:387)\n\tat org.h2.mvstore.db.MVTable.addIndex(MVTable.java:367)\n\tat org.h2.command.ddl.AlterTableAddConstraint.tryUpdate(AlterTableAddConstraint.java:149)\n\tat org.h2.command.ddl.AlterTableAddConstraint.update(AlterTableAddConstraint.java:74)\n\tat org.h2.command.ddl.AlterTable.update(AlterTable.java:46)\n\tat org.h2.command.CommandContainer.update(CommandContainer.java:169)\n\tat org.h2.command.Command.executeUpdate(Command.java:252)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createIndexes(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeVirtual(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000075346c018800.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 255\njava.lang.reflect.InvocationTargetException\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:237)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: org.h2.jdbc.JdbcSQLNonTransientConnectionException: Out of memory.; SQL statement:\n\n\nALTER TABLE STOCK ADD CONSTRAINT\n    STOCK_PK PRIMARY KEY (S_W_ID, S_I_I [90108-220]\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:690)\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:489)\n\tat org.h2.message.DbException.get(DbException.java:212)\n\tat org.h2.message.DbException.convert(DbException.java:401)\n\tat org.h2.command.Command.executeUpdate(Command.java:262)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createIndexes(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 8 more\nCaused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.h2.result.RowFactory$DefaultRowFactory.createRow(RowFactory.java:178)\n\tat org.h2.mvstore.db.MVSecondaryIndex.checkUnique(MVSecondaryIndex.java:204)\n\tat org.h2.mvstore.db.MVSecondaryIndex.add(MVSecondaryIndex.java:194)\n\tat org.h2.mvstore.db.MVTable.addRowsToIndex(MVTable.java:723)\n\tat org.h2.mvstore.db.MVTable.rebuildIndexBuffered(MVTable.java:467)\n\tat org.h2.mvstore.db.MVTable.rebuildIndex(MVTable.java:387)\n\tat org.h2.mvstore.db.MVTable.addIndex(MVTable.java:367)\n\tat org.h2.command.ddl.AlterTableAddConstraint.tryUpdate(AlterTableAddConstraint.java:149)\n\tat org.h2.command.ddl.AlterTableAddConstraint.update(AlterTableAddConstraint.java:74)\n\tat org.h2.command.ddl.AlterTable.update(AlterTable.java:46)\n\tat org.h2.command.CommandContainer.update(CommandContainer.java:169)\n\tat org.h2.command.Command.executeUpdate(Command.java:252)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createIndexes(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeVirtual(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000709f7c018800.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:237)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000709f7c001800.invokeStatic(LambdaForm$DMH)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\"\n"
                ]
            ],
            "als": [
                [
                    "G1",
                    "Error code not found: 1\n17:02:11.180 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:18:20.431 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n19:37:48.539 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'als' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.Als.setUpSparkContext(Als.scala:43)\n\tat org.renaissance.apache.spark.Als.setUpBeforeAll(Als.scala:88)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "chi-square": [
                [
                    "G1",
                    "Error code not found: 1\n16:59:38.553 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:15:16.467 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n19:33:19.617 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'chi-square' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.ChiSquare.setUpSparkContext(ChiSquare.scala:41)\n\tat org.renaissance.apache.spark.ChiSquare.setUpBeforeAll(ChiSquare.scala:86)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "dec-tree": [
                [
                    "G1",
                    "Error code not found: 1\n17:01:44.399 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:17:03.725 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n19:37:33.635 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'dec-tree' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.DecTree.setUpSparkContext(DecTree.scala:38)\n\tat org.renaissance.apache.spark.DecTree.setUpBeforeAll(DecTree.scala:89)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "gauss-mix": [
                [
                    "G1",
                    "Error code not found: 1\n17:03:08.649 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:19:09.679 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n19:38:49.277 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'gauss-mix' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.GaussMix.setUpSparkContext(GaussMix.scala:50)\n\tat org.renaissance.apache.spark.GaussMix.setUpBeforeAll(GaussMix.scala:91)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "log-regression": [
                [
                    "G1",
                    "Error code not found: 1\n17:03:05.178 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:19:06.278 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n19:38:45.727 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'log-regression' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.LogRegression.setUpSparkContext(LogRegression.scala:39)\n\tat org.renaissance.apache.spark.LogRegression.setUpBeforeAll(LogRegression.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "movie-lens": [
                [
                    "G1",
                    "Error code not found: 1\n16:59:14.155 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:14:52.853 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n19:32:54.483 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'movie-lens' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.MovieLens.setUpSparkContext(MovieLens.scala:56)\n\tat org.renaissance.apache.spark.MovieLens.setUpBeforeAll(MovieLens.scala:258)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "naive-bayes": [
                [
                    "G1",
                    "Error code not found: 1\n17:02:07.724 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:18:17.043 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n19:37:44.928 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'naive-bayes' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpSparkContext(NaiveBayes.scala:33)\n\tat org.renaissance.apache.spark.NaiveBayes.setUpBeforeAll(NaiveBayes.scala:56)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\nException in thread \"neo4j.Scheduler-1\" java.lang.OutOfMemoryError: Java heap space\n\tat java.base/jdk.internal.misc.Unsafe.allocateInstance(Native Method)\n\tat java.base/java.lang.invoke.DirectMethodHandle.allocateInstance(DirectMethodHandle.java:501)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.newInvokeSpecial(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n\tat org.neo4j.kernel.impl.scheduler.ThreadPoolManager.getThreadPool(ThreadPoolManager.java:56)\n\tat org.neo4j.kernel.impl.scheduler.ThreadPoolManager.getThreadPool(ThreadPoolManager.java:52)\n\tat org.neo4j.kernel.impl.scheduler.ScheduledJobHandle.submitIfRunnable(ScheduledJobHandle.java:148)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.scheduleDueTasks(TimeBasedTaskScheduler.java:146)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.tick(TimeBasedTaskScheduler.java:129)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.run(TimeBasedTaskScheduler.java:119)\n\tat java.base/java.lang.Thread.runWith(Thread.java:1596)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat com.fasterxml.jackson.core.util.TextBuffer.contentsAsString(TextBuffer.java:468)\n\tat com.fasterxml.jackson.core.json.ReaderBasedJsonParser.getText(ReaderBasedJsonParser.java:325)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:202)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:101)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000075abc411c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x000075abc4004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000075abc400a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.util.LinkedHashMap.newNode(LinkedHashMap.java:281)\n\tat java.base/java.util.HashMap.putVal(HashMap.java:637)\n\tat java.base/java.util.HashMap.put(HashMap.java:618)\n\tat play.api.libs.json.ImmutableLinkedHashMap$$anon$2.addOne(ImmutableLinkedHashMap.scala:77)\n\tat play.api.libs.json.ImmutableLinkedHashMap$$anon$2.$anonfun$addAll$1(ImmutableLinkedHashMap.scala:83)\n\tat play.api.libs.json.ImmutableLinkedHashMap$$anon$2$$Lambda/0x000071bcec88c908.apply(Unknown Source)\n\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)\n\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1300)\n\tat play.api.libs.json.ImmutableLinkedHashMap$$anon$2.addAll(ImmutableLinkedHashMap.scala:83)\n\tat play.api.libs.json.ImmutableLinkedHashMap$$anon$2.addAll(ImmutableLinkedHashMap.scala:64)\n\tat scala.collection.mutable.Growable.$plus$plus$eq(Growable.scala:69)\n\tat scala.collection.mutable.Growable.$plus$plus$eq$(Growable.scala:69)\n\tat play.api.libs.json.ImmutableLinkedHashMap$$anon$2.$plus$plus$eq(ImmutableLinkedHashMap.scala:64)\n\tat play.api.libs.json.JsObject$.createFieldsMap(JsValue.scala:205)\n\tat play.api.libs.json.JsObject$.apply(JsValue.scala:211)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:228)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:101)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000071bcec11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.List.$colon$colon(List.scala:97)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:244)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:101)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000076fedc11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x000076fedc004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000076fedc00a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "page-rank": [
                [
                    "G1",
                    "Error code not found: 1\n16:56:07.095 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:13:54.571 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 257425408 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n19:32:02.128 ERROR [main] org.apache.spark.SparkContext - Error initializing SparkContext.\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105) ~[apache-spark_2.13-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172) ~[renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10) [scala3-library_3-3.3.1.jar:3.3.1]\n\tat scala.collection.immutable.List.foreach(List.scala:333) [scala-library-2.13.12.jar:?]\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala) [renaissance-harness_3-0.15.0.jar:0.15.0]\n\tat jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:580) ~[?:?]\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78) [renaissance-gpl-0.15.0.jar:0.15.0]\n\tat org.renaissance.core.Launcher.main(Launcher.java:43) [renaissance-gpl-0.15.0.jar:0.15.0]\nBenchmark 'page-rank' failed with exception:\norg.apache.spark.SparkIllegalArgumentException: [INVALID_DRIVER_MEMORY] System memory 268435456 must be at least 471859200. Please increase heap size using the --driver-memory option or \"spark.driver.memory\" in Spark configuration.\n\tat org.apache.spark.memory.UnifiedMemoryManager$.getMaxMemory(UnifiedMemoryManager.scala:219)\n\tat org.apache.spark.memory.UnifiedMemoryManager$.apply(UnifiedMemoryManager.scala:201)\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:325)\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:483)\n\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888)\n\tat org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext(SparkUtil.scala:81)\n\tat org.renaissance.apache.spark.SparkUtil.setUpSparkContext$(SparkUtil.scala:54)\n\tat org.renaissance.apache.spark.PageRank.setUpSparkContext(PageRank.scala:49)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:105)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "reactors": [
                [
                    "G1",
                    "Error code not found: 1\nException in thread \"reactors-io-scheduler-reanimator\" java.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\njava.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\nBenchmark 'reactors' failed with exception:\njava.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nFailed to load benchmark 'reactors': GC overhead limit exceeded\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"reactors-io-scheduler-reanimator\"\nFailed to load benchmark 'reactors': Java heap space\n"
                ]
            ],
            "PetClinic": [
                [
                    "G1",
                    "Error code not found: 1\nError: Unable to access jarfile benchmark_apps/spring-petclinic-3.3.0-SNAPSHOT.jar\n"
                ]
            ],
            "kafka": [
                [
                    "Parallel",
                    "Error code not found: 3\n===== DaCapo 23.11-chopin kafka starting warmup 1 =====\nStarting 1000000 requests...\nCompleted requests\nFinished\n===== DaCapo 23.11-chopin kafka completed warmup 1 in 81565 msec =====\n===== DaCapo 23.11-chopin kafka starting warmup 2 =====\nStarting 1000000 requests...\nCompleted requests\nFinished\n===== DaCapo 23.11-chopin kafka completed warmup 2 in 160767 msec =====\n===== DaCapo 23.11-chopin kafka starting warmup 3 =====\nStarting 1000000 requests...\n"
                ]
            ],
            "akka-uct": [
                [
                    "Parallel",
                    "Error code not found: 255\nUncaught error from thread [UCT-akka.actor.default-dispatcher-5]: Uncaught error from thread [Uncaught error from thread [UCT-akka.actor.default-dispatcher-7]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\nUncaught error from thread [UCT-akka.actor.default-dispatcher-19]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCTUncaught error from thread [GC overhead limit exceeded, Uncaught error from thread [UCT-akka.actor.default-dispatcher-11]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUCT-akka.actor.default-dispatcher-18]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.util.Arrays.copyOfRangeByte(Arrays.java:3863)\n\tat java.base/java.util.Arrays.copyOfRange(Arrays.java:3854)\n\tat java.base/java.lang.String.<init>(String.java:4788)\n\tat java.base/java.lang.String.<init>(String.java:1507)\n\tat java.base/java.lang.StringBuilder.toString(StringBuilder.java:475)\n\tat akka.util.Helpers$.base64(Helpers.scala:103)\n\tat akka.actor.dungeon.Children.randomName(Children.scala:114)\n\tat akka.actor.dungeon.Children.randomName$(Children.scala:22)\n\tat akka.actor.ActorCell.randomName(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\nUncaught error from thread [UCT-akka.actor.default-dispatcher-10]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat scala.collection.immutable.RedBlackTree$Tree.withLeft(RedBlackTree.scala:681)\n\tat scala.collection.immutable.RedBlackTree$.balanceLeft(RedBlackTree.scala:362)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.update(RedBlackTree.scala:175)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.add(ChildrenContainer.scala:113)\n\tat akka.actor.dungeon.Children.initChild(Children.scala:161)\n\tat akka.actor.dungeon.Children.initChild$(Children.scala:22)\n\tat akka.actor.ActorCell.initChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:324)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\nUncaught error from thread [Uncaught error from thread [UCT-akka.actor.default-dispatcher-12]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.lang.StringBuilder.toString(StringBuilder.java:475)\n\tat akka.util.Helpers$.base64(Helpers.scala:103)\n\tat akka.actor.dungeon.Children.randomName(Children.scala:114)\n\tat akka.actor.dungeon.Children.randomName$(Children.scala:22)\n\tat akka.actor.ActorCell.randomName(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateUrgentChildren(UctAkkaActorBenchmark.scala:323)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:249)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\nUncaught error from thread [UCT-akka.actor.default-dispatcher-19]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-14]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nshutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled forUCT-akka.actor.default-dispatcher-20]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-6]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUncaught error from thread [UCT-akka.actor.default-dispatcher-8]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[Uncaught error from thread [UCT-akka.actor.internal-dispatcher-4]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUCT-akka.actor.default-dispatcher-13]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat scala.collection.immutable.RedBlackTree$Tree.withLeft(RedBlackTree.scala:681)\n\tat scala.collection.immutable.RedBlackTree$.balanceLeft(RedBlackTree.scala:362)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.update(RedBlackTree.scala:175)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.reserve(ChildrenContainer.scala:135)\n\tat akka.actor.dungeon.Children.reserveChild(Children.scala:146)\n\tat akka.actor.dungeon.Children.reserveChild$(Children.scala:22)\n\tat akka.actor.ActorCell.reserveChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:299)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\nUCTUncaught error from thread []\njava.lang.OutOfMemoryError: GC overhead limit exceeded\nUCT-akka.actor.default-dispatcher-15]: GC overhead limit exceeded, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n"
                ],
                [
                    "Z",
                    "Error code not found: 255\nUncaught error from thread [UCT-akka.actor.default-dispatcher-7]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.RedBlackTree$Tree.withLeft(RedBlackTree.scala:681)\n\tat scala.collection.immutable.RedBlackTree$.balanceLeft(RedBlackTree.scala:362)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.update(RedBlackTree.scala:175)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.reserve(ChildrenContainer.scala:135)\n\tat akka.actor.dungeon.Children.reserveChild(Children.scala:146)\n\tat akka.actor.dungeon.Children.reserveChild$(Children.scala:22)\n\tat akka.actor.ActorCell.reserveChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:299)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\nUncaught error from thread [UCT-akka.actor.default-dispatcher-20]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\n\tat akka.actor.LocalActorRefProvider.actorOf(ActorRefProvider.scala:702)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:312)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\nUncaught error from thread [UCT-akka.actor.default-dispatcher-10]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCTUncaught error from thread [UCT-akka.actor.default-dispatcher-14]: Java heap space, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[UCT]\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.RedBlackTree$Tree.withRight(RedBlackTree.scala:690)\n\tat scala.collection.immutable.RedBlackTree$.balanceRight(RedBlackTree.scala:397)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:419)\n\tat scala.collection.immutable.RedBlackTree$.upd(RedBlackTree.scala:417)\n\tat scala.collection.immutable.RedBlackTree$.update(RedBlackTree.scala:175)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.add(ChildrenContainer.scala:113)\n\tat akka.actor.dungeon.Children.initChild(Children.scala:161)\n\tat akka.actor.dungeon.Children.initChild$(Children.scala:22)\n\tat akka.actor.ActorCell.initChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:324)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n]\njava.lang.OutOfMemoryError: Java heap space\n\tat scala.collection.immutable.TreeMap.newMapOrSelf(TreeMap.scala:83)\n\tat scala.collection.immutable.TreeMap.updated(TreeMap.scala:139)\n\tat akka.actor.dungeon.ChildrenContainer$NormalChildrenContainer.add(ChildrenContainer.scala:113)\n\tat akka.actor.dungeon.Children.initChild(Children.scala:161)\n\tat akka.actor.dungeon.Children.initChild$(Children.scala:22)\n\tat akka.actor.ActorCell.initChild(ActorCell.scala:410)\n\tat akka.actor.dungeon.Children.makeChild(Children.scala:324)\n\tat akka.actor.dungeon.Children.attachChild(Children.scala:50)\n\tat akka.actor.dungeon.Children.attachChild$(Children.scala:22)\n\tat akka.actor.ActorCell.attachChild(ActorCell.scala:410)\n\tat akka.actor.ActorSystemImpl.actorOf(ActorSystem.scala:905)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor$.createNodeActor(UctAkkaActorBenchmark.scala:217)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.generateChildren(UctAkkaActorBenchmark.scala:291)\n\tat edu.rice.habanero.benchmarks.uct.UctAkkaActorBenchmark$NodeActor.process(UctAkkaActorBenchmark.scala:244)\n\tat edu.rice.habanero.actors.AkkaActor$$anon$1.applyOrElse(AkkaActor.scala:33)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:537)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:471)\n\tat edu.rice.habanero.actors.AkkaActor.aroundReceive(AkkaActor.scala:17)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:547)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:231)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:243)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)\n"
                ]
            ],
            "scala-stm-bench7": [
                [
                    "Parallel",
                    "Error code not found: 1\nSetup start...\nSetting up the design library:\nException in thread \"Thread-2\" java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat java.base/java.util.zip.InflaterInputStream.<init>(InflaterInputStream.java:89)\n\tat java.base/java.util.zip.ZipFile$ZipFileInflaterInputStream.<init>(ZipFile.java:440)\n\tat java.base/java.util.zip.ZipFile$ZipFileInflaterInputStream.<init>(ZipFile.java:434)\n\tat java.base/java.util.zip.ZipFile.getInputStream(ZipFile.java:401)\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Thread-2\"\nException in thread \"main\" java.lang.OutOfMemoryError: GC overhead limit exceeded\nException in thread \"Logging-Cleaner\" java.lang.OutOfMemoryError: GC overhead limit exceeded\nException in thread \"Thread-0\" java.lang.OutOfMemoryError: GC overhead limit exceeded\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nSetup start...\nSetting up the design library:\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Thread-2\"\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\"\n"
                ]
            ]
        },
        "512": {
            "h2": [
                [
                    "G1",
                    "Return code -9: Process was killed due to timeout\n===== DaCapo 23.11-chopin h2 starting warmup 1 =====\nStarting 100000 requests...\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 255\njava.lang.reflect.InvocationTargetException\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:237)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: org.h2.jdbc.JdbcSQLNonTransientConnectionException: Out of memory.; SQL statement:\n\n\nALTER TABLE ORDERLINE ADD CONSTRAINT\n    OL_O_FK FOREIGN KEY (OL_W_ID, OL_D_ID, OL_O_ID) REFERENCES ORDE [90108-220]\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:690)\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:489)\n\tat org.h2.message.DbException.get(DbException.java:212)\n\tat org.h2.message.DbException.convert(DbException.java:401)\n\tat org.h2.command.Command.executeUpdate(Command.java:262)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createConstraints(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 8 more\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.h2.mvstore.RootReference.updateRootPage(RootReference.java:131)\n\tat org.h2.mvstore.MVMap.operate(MVMap.java:1865)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:363)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:350)\n\tat org.h2.mvstore.tx.TransactionMap.put(TransactionMap.java:265)\n\tat org.h2.mvstore.db.MVSecondaryIndex.add(MVSecondaryIndex.java:188)\n\tat org.h2.mvstore.db.MVTable.addRowsToIndex(MVTable.java:723)\n\tat org.h2.mvstore.db.MVTable.rebuildIndexBuffered(MVTable.java:467)\n\tat org.h2.mvstore.db.MVTable.rebuildIndex(MVTable.java:387)\n\tat org.h2.mvstore.db.MVTable.addIndex(MVTable.java:367)\n\tat org.h2.command.ddl.AlterTableAddConstraint.createIndex(AlterTableAddConstraint.java:368)\n\tat org.h2.command.ddl.AlterTableAddConstraint.tryUpdate(AlterTableAddConstraint.java:269)\n\tat org.h2.command.ddl.AlterTableAddConstraint.update(AlterTableAddConstraint.java:74)\n\tat org.h2.command.ddl.AlterTable.update(AlterTable.java:46)\n\tat org.h2.command.CommandContainer.update(CommandContainer.java:169)\n\tat org.h2.command.Command.executeUpdate(Command.java:252)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createConstraints(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeVirtual(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007b6d43018800.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n"
                ],
                [
                    "Z",
                    "Error code not found: 255\njava.lang.reflect.InvocationTargetException\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.dacapo.harness.H2.preIteration(H2.java:95)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:237)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: org.h2.jdbc.JdbcSQLNonTransientConnectionException: Out of memory.; SQL statement:\n\n\nALTER TABLE ORDERLINE ADD CONSTRAINT\n    OL_O_FK FOREIGN KEY (OL_W_ID, OL_D_ID, OL_O_ID) REFERENCES ORDE [90108-220]\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:690)\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:489)\n\tat org.h2.message.DbException.get(DbException.java:212)\n\tat org.h2.message.DbException.convert(DbException.java:401)\n\tat org.h2.command.Command.executeUpdate(Command.java:262)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createConstraints(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 8 more\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.h2.mvstore.Page$NonLeaf.setChild(Page.java:1197)\n\tat org.h2.mvstore.MVMap.replacePage(MVMap.java:1360)\n\tat org.h2.mvstore.MVMap.operate(MVMap.java:1863)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:363)\n\tat org.h2.mvstore.tx.TransactionMap.set(TransactionMap.java:350)\n\tat org.h2.mvstore.tx.TransactionMap.put(TransactionMap.java:265)\n\tat org.h2.mvstore.db.MVSecondaryIndex.add(MVSecondaryIndex.java:188)\n\tat org.h2.mvstore.db.MVTable.addRowsToIndex(MVTable.java:723)\n\tat org.h2.mvstore.db.MVTable.rebuildIndexBuffered(MVTable.java:467)\n\tat org.h2.mvstore.db.MVTable.rebuildIndex(MVTable.java:387)\n\tat org.h2.mvstore.db.MVTable.addIndex(MVTable.java:367)\n\tat org.h2.command.ddl.AlterTableAddConstraint.createIndex(AlterTableAddConstraint.java:368)\n\tat org.h2.command.ddl.AlterTableAddConstraint.tryUpdate(AlterTableAddConstraint.java:269)\n\tat org.h2.command.ddl.AlterTableAddConstraint.update(AlterTableAddConstraint.java:74)\n\tat org.h2.command.ddl.AlterTable.update(AlterTable.java:46)\n\tat org.h2.command.CommandContainer.update(CommandContainer.java:169)\n\tat org.h2.command.Command.executeUpdate(Command.java:252)\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:252)\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)\n\tat org.h2.tools.RunScript.execute(RunScript.java:169)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.runScript(Unknown Source)\n\tat org.dacapo.h2.TPCC.createConstraints(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIterationMemoryDB(Unknown Source)\n\tat org.dacapo.h2.TPCC.preIteration(Unknown Source)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.invokeVirtual(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000752424018800.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"Logging-Cleaner\"\n"
                ]
            ],
            "naive-bayes": [
                [
                    "G1",
                    "Error code not found: 52\n17:13:50.883 WARN  [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] org.apache.spark.storage.BlockManager - Block rdd_3_1 could not be removed as it was not found on disk or in memory\n17:13:50.933 ERROR [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] org.apache.spark.executor.Executor - Exception in task 1.0 in stage 0.0 (TID 1)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007de338b2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007de338bf1520.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n17:13:51.117 ERROR [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#82,Executor task launch worker for task 1.0 in stage 0.0 (TID 1),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007de338b2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007de338bf1520.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 52\n18:32:47.004 WARN  [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.storage.BlockManager - Block rdd_3_7 could not be removed as it was not found on disk or in memory\n18:32:47.169 ERROR [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.executor.Executor - Exception in task 7.0 in stage 0.0 (TID 7)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.build(ColumnBuilder.scala:81) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build(NullableColumnBuilder.scala:67) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build$(NullableColumnBuilder.scala:66) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.$anonfun$next$5(InMemoryRelation.scala:115) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1$$Lambda/0x00007982dbeb65c0.apply(Unknown Source) ~[?:?]\n\tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:934) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:114) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007982dbb2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007982dbbf2e20.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n18:32:48.072 ERROR [Executor task launch worker for task 7.0 in stage 0.0 (TID 7)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#83,Executor task launch worker for task 7.0 in stage 0.0 (TID 7),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.build(ColumnBuilder.scala:81) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build(NullableColumnBuilder.scala:67) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build$(NullableColumnBuilder.scala:66) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.$anonfun$next$5(InMemoryRelation.scala:115) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1$$Lambda/0x00007982dbeb65c0.apply(Unknown Source) ~[?:?]\n\tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:934) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:114) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007982dbb2d018.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007982dbbf2e20.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n"
                ],
                [
                    "Z",
                    "Error code not found: 52\n19:56:24.042 WARN  [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] org.apache.spark.storage.BlockManager - Block rdd_3_4 could not be removed as it was not found on disk or in memory\n19:56:24.242 ERROR [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] org.apache.spark.executor.Executor - Exception in task 4.0 in stage 0.0 (TID 4)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.build(ColumnBuilder.scala:81) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build(NullableColumnBuilder.scala:67) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build$(NullableColumnBuilder.scala:66) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.$anonfun$next$5(InMemoryRelation.scala:115) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1$$Lambda/0x00007a08dcec65c0.apply(Unknown Source) ~[?:?]\n\tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:934) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:114) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007a08dcb299e0.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007a08dcbf2228.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n19:56:24.858 ERROR [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#84,Executor task launch worker for task 4.0 in stage 0.0 (TID 4),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.build(ColumnBuilder.scala:81) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build(NullableColumnBuilder.scala:67) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.build$(NullableColumnBuilder.scala:66) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.build(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.$anonfun$next$5(InMemoryRelation.scala:115) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1$$Lambda/0x00007a08dcec65c0.apply(Unknown Source) ~[?:?]\n\tat scala.collection.ArrayOps$.map$extension(ArrayOps.scala:934) ~[scala-library-2.13.12.jar:?]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:114) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x00007a08dcb299e0.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x00007a08dcbf2228.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n"
                ]
            ],
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.allocateTable(LongObjectHashMap.java:3022)\n\tat org.neo4j.collection.trackable.HeapTrackingLongObjectHashMap.allocateTable(HeapTrackingLongObjectHashMap.java:62)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehash(LongObjectHashMap.java:2908)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehashAndGrow(LongObjectHashMap.java:2900)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.addKeyValueAtIndex(LongObjectHashMap.java:2742)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.getIfAbsentPut(LongObjectHashMap.java:2357)\n\tat org.neo4j.kernel.impl.api.state.TxState.getOrCreateNodeState(TxState.java:673)\n\tat org.neo4j.kernel.impl.api.state.TxState.getOrCreateNodeStateLabelDiffSets(TxState.java:337)\n\tat org.neo4j.kernel.impl.api.state.TxState.nodeDoAddLabel(TxState.java:499)\n\tat org.neo4j.kernel.impl.newapi.Operations.checkConstraintsAndAddLabelToNode(Operations.java:420)\n\tat org.neo4j.kernel.impl.newapi.Operations.nodeCreateWithLabels(Operations.java:276)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.createNode(TransactionImpl.java:208)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.$anonfun$populateVertices$1(AnalyticsBenchmark.scala:73)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.$anonfun$populateVertices$1$adapted(AnalyticsBenchmark.scala:72)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark$$Lambda/0x00007acf683913c8.apply(Unknown Source)\n\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)\n\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:933)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:72)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007acf6811c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007acf68004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007acf6800a000.invoke(LambdaForm$MH)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat play.api.libs.json.JsSuccess$.apply$default$2(JsResult.scala:12)\n\tat play.api.libs.json.BigDecimalParser$.parse(BigDecimalParser.scala:26)\n\tat play.api.libs.json.jackson.JsValueDeserializer.parseBigDecimal(JacksonJson.scala:170)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:200)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:102)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007ea61811c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007ea618004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007ea61800a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nException in thread \"neo4j.Scheduler-1\" java.lang.OutOfMemoryError: Java heap space\n\tat java.base/jdk.internal.misc.Unsafe.allocateInstance(Native Method)\n\tat java.base/java.lang.invoke.DirectMethodHandle.allocateInstance(DirectMethodHandle.java:501)\n\tat java.base/java.lang.invoke.DirectMethodHandle$Holder.newInvokeSpecial(DirectMethodHandle$Holder)\n\tat java.base/java.lang.invoke.Invokers$Holder.linkToTargetMethod(Invokers$Holder)\n\tat org.neo4j.kernel.impl.scheduler.ThreadPoolManager.getThreadPool(ThreadPoolManager.java:56)\n\tat org.neo4j.kernel.impl.scheduler.ThreadPoolManager.getThreadPool(ThreadPoolManager.java:52)\n\tat org.neo4j.kernel.impl.scheduler.ScheduledJobHandle.submitIfRunnable(ScheduledJobHandle.java:148)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.scheduleDueTasks(TimeBasedTaskScheduler.java:146)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.tick(TimeBasedTaskScheduler.java:129)\n\tat org.neo4j.kernel.impl.scheduler.TimeBasedTaskScheduler.run(TimeBasedTaskScheduler.java:119)\n\tat java.base/java.lang.Thread.runWith(Thread.java:1596)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat play.api.libs.json.jackson.JsValueDeserializer.parseBigDecimal(JacksonJson.scala:172)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:200)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:158)\n\tat play.api.libs.json.jackson.JsValueDeserializer.deserialize(JacksonJson.scala:153)\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n\tat com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:4801)\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2974)\n\tat play.api.libs.json.jackson.JacksonJson.parseJsValue(JacksonJson.scala:296)\n\tat play.api.libs.json.StaticBinding$.parseJsValue(StaticBinding.scala:17)\n\tat play.api.libs.json.Json$.parse(Json.scala:175)\n\tat org.renaissance.neo4j.Neo4jAnalytics.loadJsonResource(Neo4jAnalytics.scala:82)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:102)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007c0d2811c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007c0d28004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007c0d2800a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ]
            ],
            "page-rank": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.io.BufferedReader.implReadLine(BufferedReader.java:403)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:347)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:436)\n\tat scala.io.BufferedSource$BufferedLineIterator.hasNext(BufferedSource.scala:73)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:653)\n\tat scala.collection.immutable.List.prependedAll(List.scala:155)\n\tat scala.collection.immutable.List$.from(List.scala:684)\n\tat scala.collection.immutable.List$.from(List.scala:681)\n\tat scala.collection.SeqFactory$Delegate.from(Factory.scala:306)\n\tat scala.collection.immutable.Seq$.from(Seq.scala:42)\n\tat scala.collection.IterableOnceOps.toSeq(IterableOnce.scala:1326)\n\tat scala.collection.IterableOnceOps.toSeq$(IterableOnce.scala:1326)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1300)\n\tat org.renaissance.apache.spark.PageRank.copyLinesToFile(PageRank.scala:87)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:114)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x00007719b011c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x00007719b0004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x00007719b000a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\n18:25:40.638 WARN  [dispatcher-HeartbeatReceiver] org.apache.spark.HeartbeatReceiver - Removing executor driver with no recent heartbeats: 133871 ms exceeds timeout 120000 ms\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.lang.StringUTF16.compress(StringUTF16.java:161)\n\tat java.base/java.lang.String.<init>(String.java:4768)\n\tat java.base/java.lang.String.<init>(String.java:303)\n\tat java.base/java.io.BufferedReader.implReadLine(BufferedReader.java:403)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:347)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:436)\n\tat scala.io.BufferedSource$BufferedLineIterator.hasNext(BufferedSource.scala:73)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:653)\n\tat scala.collection.immutable.List.prependedAll(List.scala:155)\n\tat scala.collection.immutable.List$.from(List.scala:684)\n\tat scala.collection.immutable.List$.from(List.scala:681)\n\tat scala.collection.SeqFactory$Delegate.from(Factory.scala:306)\n\tat scala.collection.immutable.Seq$.from(Seq.scala:42)\n\tat scala.collection.IterableOnceOps.toSeq(IterableOnce.scala:1326)\n\tat scala.collection.IterableOnceOps.toSeq$(IterableOnce.scala:1326)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1300)\n\tat org.renaissance.apache.spark.PageRank.copyLinesToFile(PageRank.scala:87)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:114)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x0000746a2411c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000746a24004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000746a2400a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n18:25:40.643 WARN  [dispatcher-HeartbeatReceiver] org.apache.spark.rpc.netty.NettyRpcEnv - Ignored message: true\n18:25:40.644 WARN  [kill-executor-thread] org.apache.spark.SparkContext - Killing executors is not supported by current scheduler.\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nBenchmark 'page-rank' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.io.BufferedReader.implReadLine(BufferedReader.java:403)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:347)\n\tat java.base/java.io.BufferedReader.readLine(BufferedReader.java:436)\n\tat scala.io.BufferedSource$BufferedLineIterator.hasNext(BufferedSource.scala:73)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:653)\n\tat scala.collection.immutable.List.prependedAll(List.scala:155)\n\tat scala.collection.immutable.List$.from(List.scala:684)\n\tat scala.collection.immutable.List$.from(List.scala:681)\n\tat scala.collection.SeqFactory$Delegate.from(Factory.scala:306)\n\tat scala.collection.immutable.Seq$.from(Seq.scala:42)\n\tat scala.collection.IterableOnceOps.toSeq(IterableOnce.scala:1326)\n\tat scala.collection.IterableOnceOps.toSeq$(IterableOnce.scala:1326)\n\tat scala.collection.AbstractIterator.toSeq(Iterator.scala:1300)\n\tat org.renaissance.apache.spark.PageRank.copyLinesToFile(PageRank.scala:87)\n\tat org.renaissance.apache.spark.PageRank.setUpBeforeAll(PageRank.scala:114)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x0000790ccc11c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000790ccc004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000790ccc00a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n"
                ]
            ],
            "reactors": [
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'reactors' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat io.reactors.Reactor$.apply(Reactor.scala:261)\n\tat org.renaissance.actors.ForkJoinCreation$.$anonfun$run$17(Reactors.scala:314)\n\tat org.renaissance.actors.ForkJoinCreation$.$anonfun$run$17$adapted(Reactors.scala:313)\n\tat org.renaissance.actors.ForkJoinCreation$$$Lambda/0x000070aff42879d8.apply(Unknown Source)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n\tat scala.collection.TraversableLike$$Lambda/0x000070aff41ceef0.apply(Unknown Source)\n\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n\tat org.renaissance.actors.ForkJoinCreation$.run(Reactors.scala:313)\n\tat org.renaissance.actors.Reactors.run(Reactors.scala:68)\n\tat org.renaissance.harness.ExecutionDriver.executeOperation(ExecutionDriver.java:137)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:93)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000070aff411c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x000070aff4004000.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x000070aff400a000.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\njava.lang.OutOfMemoryError: Java heap space\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-8\" java.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-5\" java.lang.NoClassDefFoundError: Could not initialize class java.lang.StackTraceElement$HashedModules\njava.lang.OutOfMemoryError: Java heap space\nException in thread \"reactors-io-scheduler-ForkJoinPool-1-worker-4\" java.lang.NoClassDefFoundError: Could not initialize class java.lang.StackTraceElement$HashedModules\nException in thread \"reactors-io-scheduler-reanimator\" java.lang.NullPointerException: Cannot invoke \"java.lang.Thread$UncaughtExceptionHandler.uncaughtException(java.lang.Thread, java.lang.Throwable)\" because the return value of \"io.reactors.JvmScheduler$ReactorForkJoinPool.getUncaughtExceptionHandler()\" is null\n\tat io.reactors.JvmScheduler$ReactorForkJoinReanimatorThread.run(JvmScheduler.scala:51)\njava.lang.OutOfMemoryError: Java heap space\njava.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects\nBenchmark 'reactors' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n"
                ]
            ]
        },
        "1024": {
            "neo4j-analytics": [
                [
                    "G1",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\norg.neo4j.graphdb.TransientTransactionFailureException: Unable to complete transaction.: The memory pool limit was exceeded. The corresponding setting can be found in the error message\n\tat org.neo4j.kernel.impl.coreapi.DefaultTransactionExceptionMapper.mapException(DefaultTransactionExceptionMapper.java:52)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:337)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks(RenaissanceSuite.scala:205)\n\tat org.renaissance.harness.RenaissanceSuite$.main(RenaissanceSuite.scala:130)\n\tat org.renaissance.harness.RenaissanceSuite.main(RenaissanceSuite.scala)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.renaissance.core.Launcher.loadAndInvokeHarnessClass(Launcher.java:129)\n\tat org.renaissance.core.Launcher.launchHarnessClass(Launcher.java:78)\n\tat org.renaissance.core.Launcher.main(Launcher.java:43)\nCaused by: org.neo4j.memory.MemoryLimitExceededException: The allocation of an extra 2.0 MiB would use more than the limit 716.8 MiB. Currently using 716.0 MiB. dbms.memory.transaction.total.max threshold reached\n\tat org.neo4j.memory.MemoryPoolImpl.reserveMemory(MemoryPoolImpl.java:90)\n\tat org.neo4j.memory.MemoryPoolImpl.reserveHeap(MemoryPoolImpl.java:74)\n\tat org.neo4j.memory.DelegatingMemoryPool.reserveHeap(DelegatingMemoryPool.java:31)\n\tat org.neo4j.memory.DatabaseMemoryGroupTracker.reserveHeap(DatabaseMemoryGroupTracker.java:65)\n\tat org.neo4j.kernel.impl.api.TransactionMemoryPool.reserveHeap(TransactionMemoryPool.java:90)\n\tat org.neo4j.memory.LocalMemoryTracker.reserveHeapFromPool(LocalMemoryTracker.java:264)\n\tat org.neo4j.memory.LocalMemoryTracker.allocateHeap(LocalMemoryTracker.java:183)\n\tat org.neo4j.internal.recordstorage.Loaders$2.copy(Loaders.java:207)\n\tat org.neo4j.internal.recordstorage.Loaders$2.copy(Loaders.java:181)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.ensureHasBeforeRecordImage(RecordChanges.java:217)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.prepareForChange(RecordChanges.java:170)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.forChangingData(RecordChanges.java:166)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:137)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\t... 18 more\n"
                ],
                [
                    "Parallel",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.neo4j.kernel.impl.store.record.PropertyRecord.<init>(PropertyRecord.java:71)\n\tat org.neo4j.kernel.impl.store.record.PropertyRecord.<init>(PropertyRecord.java:88)\n\tat org.neo4j.internal.recordstorage.Loaders$2.copy(Loaders.java:208)\n\tat org.neo4j.internal.recordstorage.Loaders$2.copy(Loaders.java:181)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.ensureHasBeforeRecordImage(RecordChanges.java:217)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.prepareForChange(RecordChanges.java:170)\n\tat org.neo4j.internal.recordstorage.RecordChanges$RecordChange.forChangingData(RecordChanges.java:166)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:137)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl$$Lambda/0x000071acb673b9a0.perform(Unknown Source)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x000071acb611c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n"
                ],
                [
                    "Z",
                    "Error code not found: 1\nBenchmark 'neo4j-analytics' failed with exception:\njava.lang.OutOfMemoryError: Java heap space\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.allocateTable(LongObjectHashMap.java:3021)\n\tat org.neo4j.collection.trackable.HeapTrackingLongObjectHashMap.allocateTable(HeapTrackingLongObjectHashMap.java:62)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehash(LongObjectHashMap.java:2908)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.rehashAndGrow(LongObjectHashMap.java:2900)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.addKeyValueAtIndex(LongObjectHashMap.java:2742)\n\tat org.eclipse.collections.impl.map.mutable.primitive.LongObjectHashMap.put(LongObjectHashMap.java:2190)\n\tat org.neo4j.internal.recordstorage.RecordChanges.create(RecordChanges.java:121)\n\tat org.neo4j.internal.recordstorage.PropertyCreator.primitiveSetProperty(PropertyCreator.java:136)\n\tat org.neo4j.internal.recordstorage.TransactionRecordState.nodeAddProperty(TransactionRecordState.java:461)\n\tat org.neo4j.internal.recordstorage.TransactionToRecordStateVisitor.visitNodePropertyChanges(TransactionToRecordStateVisitor.java:101)\n\tat org.neo4j.storageengine.api.txstate.TxStateVisitor$Delegator.visitNodePropertyChanges(TxStateVisitor.java:160)\n\tat org.neo4j.kernel.impl.api.state.TxState.accept(TxState.java:203)\n\tat org.neo4j.internal.recordstorage.RecordStorageEngine.createCommands(RecordStorageEngine.java:472)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.extractCommands(KernelTransactionImplementation.java:1033)\n\tat org.neo4j.kernel.impl.api.commit.DefaultCommitter.commit(DefaultCommitter.java:85)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commitTransaction(KernelTransactionImplementation.java:1002)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.closeTransaction(KernelTransactionImplementation.java:878)\n\tat org.neo4j.kernel.impl.api.KernelTransactionImplementation.commit(KernelTransactionImplementation.java:851)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.lambda$commit$0(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl$$Lambda/0x0000780b00780c78.perform(Unknown Source)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.safeTerminalOperation(TransactionImpl.java:322)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:175)\n\tat org.neo4j.kernel.impl.coreapi.TransactionImpl.commit(TransactionImpl.java:170)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateVertices(AnalyticsBenchmark.scala:97)\n\tat org.renaissance.neo4j.analytics.AnalyticsBenchmark.populateDatabase(AnalyticsBenchmark.scala:54)\n\tat org.renaissance.neo4j.Neo4jAnalytics.setUpBeforeAll(Neo4jAnalytics.scala:104)\n\tat org.renaissance.harness.ExecutionDriver.executeBenchmark(ExecutionDriver.java:82)\n\tat org.renaissance.harness.RenaissanceSuite$.runBenchmarks$$anonfun$1(RenaissanceSuite.scala:172)\n\tat org.renaissance.harness.RenaissanceSuite$$$Lambda/0x0000780b0011c4c0.applyVoid(Unknown Source)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)\n\tat scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)\n\tat scala.collection.immutable.List.foreach(List.scala:333)\n"
                ]
            ],
            "h2": [
                [
                    "Z",
                    "Error code not found: 255\n===== DaCapo 23.11-chopin h2 starting warmup 1 =====\nStarting 100000 requests...\nCompleted requests\n===== DaCapo 23.11-chopin h2 completed warmup 1 in 152765 msec =====\njava.lang.reflect.InvocationTargetException\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat Harness.main(Unknown Source)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.dacapo.harness.LatencyReporter.reportLatency(LatencyReporter.java:146)\n\tat org.dacapo.harness.Benchmark.postIteration(Benchmark.java:730)\n\tat org.dacapo.harness.H2.postIteration(H2.java:118)\n\tat org.dacapo.harness.Benchmark.run(Benchmark.java:264)\n\tat org.dacapo.harness.TestHarness.runBenchmark(TestHarness.java:225)\n\tat org.dacapo.harness.TestHarness.main(TestHarness.java:170)\n\tat java.base/java.lang.invoke.LambdaForm$DMH/0x0000733e58001800.invokeStatic(LambdaForm$DMH)\n\tat java.base/java.lang.invoke.LambdaForm$MH/0x0000733e58002c00.invoke(LambdaForm$MH)\n\tat java.base/java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(DirectMethodHandleAccessor.java:154)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\t... 2 more\n"
                ]
            ]
        }
    }
}