{
    "garbage_collector": "Z",
    "jdk": "GraalVM_21.0.4",
    "benchmark_group": "Renaissance",
    "benchmark_name": "naive-bayes",
    "heap_size": "512",
    "error": "Error code not found: 52\n15:42:30.624 WARN  [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.storage.BlockManager - Block rdd_3_3 could not be removed as it was not found on disk or in memory\n15:42:30.878 ERROR [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.executor.Executor - Exception in task 3.0 in stage 0.0 (TID 3)\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x0000000080c1f2c8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x0000000080ce76a0.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n15:42:31.246 ERROR [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] org.apache.spark.util.SparkUncaughtExceptionHandler - Uncaught exception in thread Thread[#83,Executor task launch worker for task 3.0 in stage 0.0 (TID 3),5,main]\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:71) ~[?:?]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:391) ~[?:?]\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:167) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:73) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom(NullableColumnBuilder.scala:61) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder.appendFrom$(NullableColumnBuilder.scala:54) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:93) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:105) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.next(InMemoryRelation.scala:80) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:288) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$2.next(InMemoryRelation.scala:285) ~[spark-sql_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1601) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager$$Lambda/0x0000000080c1f2c8.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1528) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1592) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1389) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdateRDDBlock(BlockManager.scala:1343) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda/0x0000000080ce76a0.apply(Unknown Source) ~[?:?]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) ~[spark-common-utils_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623) ~[spark-core_2.13-3.5.0.jar:3.5.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\n",
    "avg_cpu_usage": 33.5,
    "avg_cpu_time": 53.2,
    "avg_io_time": 0.0,
    "p90_io": 0.0,
    "number_of_pauses": 0,
    "total_pause_time": 0,
    "avg_pause_time": 0,
    "pauses_per_category": {},
    "total_pause_time_per_category": {},
    "avg_pause_time_per_category": {},
    "p90_pause_time": 0,
    "throughput": 0
}