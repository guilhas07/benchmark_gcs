{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe35d3-f7fc-4121-bcbc-0c3ece22c6ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af250670-61a6-423c-a2ae-1847fdac3339",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path(\"graphs\").glob(\"**/*.png\"):\n",
    "    file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6f121-c68d-47f1-bf99-82f661d3f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = Path(\"benchmark_matrix\")\n",
    "with open(dir / \"Graal_11_10_0_19.json\") as f:\n",
    "    graal = json.loads(f.read())[\"matrix\"]\n",
    "with open(dir / \"HotSpot_11_10_0_19.json\") as f:\n",
    "    hotspot = json.loads(f.read())[\"matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644b2f0-c21f-4951-941f-ceab57f63da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(key, d, file_title, y_label, y_limit, layout=None):\n",
    "    x_labels = list(d.keys())\n",
    "    x = np.arange(len(x_labels))\n",
    "    fig, ax = plt.subplots(figsize=(20, 10), layout=layout, dpi=300)\n",
    "    \n",
    "    gcs = sorted(graal[x_labels[0]])\n",
    "    #def plot_sub_graph(ax, key, d, gcs, title, y_label, y_limit):\n",
    "    width = 0.3\n",
    "    multiplier = 0\n",
    "    for gc in gcs:\n",
    "        values = [value[gc][key] for value in d.values()]\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, values, width, label=gc)\n",
    "        ax.bar_label(rects)\n",
    "        multiplier += 1\n",
    "        ## Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel(\"Heap Sizes (MB)\")\n",
    "        #ax.set_title(title)\n",
    "        ax.set_xticks(x + width, x_labels)\n",
    "        ax.legend(ncols=3, fontsize=20)\n",
    "        ax.set_ylim(0, y_limit)\n",
    "        fig.savefig(f\"graphs/{file_title}.png\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4607f4-07cd-416b-9e40-82a8bfd4026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(\"throughput\", graal,  \"throughput_graalvm\", \"Throughput\", 2, \"tight\")\n",
    "plot_matrix(\"throughput\", hotspot, \"throughput_hotspot\", \"Throughput\", 2, \"tight\")\n",
    "plot_matrix(\"pause_time\", graal, \"pause_time_graalvm\", \"Pause Time\", 2, \"tight\")\n",
    "plot_matrix(\"pause_time\", hotspot,  \"pause_time_hotspot\", \"Pause Time\",2.6, \"tight\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1fa9d-7205-4617-9e65-9298570656be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_benchmarks(jdk, benchmark_group):\n",
    "    benchmarks = {}\n",
    "    files = [f for f in Path(\".\").glob(\"benchmark_stats/*.json\") if jdk in f.name and benchmark_group in f.name and \"error\" not in f.name]\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            benchmark = json.loads(f.read())\n",
    "            heap_size = benchmark[\"heap_size\"]\n",
    "            name = benchmark[\"benchmark_name\"]\n",
    "            gc = benchmark[\"garbage_collector\"]\n",
    "            throughput =  benchmark[\"throughput\"]\n",
    "            pause_time =  benchmark[\"p90_pause_time\"]\n",
    "            a = benchmarks.setdefault(heap_size, {}).setdefault(name, {}).setdefault(gc, {})\n",
    "            a[\"throughput\"] = throughput / 1e9\n",
    "            a[\"pause_time\"] = pause_time / 1e9\n",
    "            \n",
    "    # filter results not valid for all 3 GCs\n",
    "    #print(\"Before\", str(benchmarks)[:500])\n",
    "    for key, value in list(benchmarks.items()):\n",
    "        for k, v in list(value.items()):\n",
    "           #print(f\"Key={k} Value={v}\")\n",
    "           if len(v) != 3 or k == \"spring\": # filter spring\n",
    "               #print(f\"Deleting with keys: {key},{k}: {benchmarks[key][k]}\")\n",
    "               del benchmarks[key][k]\n",
    "               #print(f\"After delete with keys: {key},{k}: {benchmarks[key].get(k)}\")\n",
    "           #else:\n",
    "           #    benchmarks[key] = dict(sorted(value.items()))\n",
    "    for key in list(benchmarks):\n",
    "        #print(f\"Before: {benchmarks[key]}\")\n",
    "        benchmarks[key] = dict(sorted(benchmarks[key].items()))\n",
    "        #print(f\"After: {benchmarks[key]}\")\n",
    "\n",
    "    # assert everything is sorted\n",
    "    # heap_size : name: gc\n",
    "    for key in benchmarks:\n",
    "        assert list(benchmarks[key].keys()) == sorted(list(benchmarks[key].keys())), f\"Error: {list(benchmarks[key].keys())=} != {sorted(list(benchmarks[key].keys()))=}\"\n",
    "        #print(benchmarks[key].keys())\n",
    "        for name in benchmarks[key]:\n",
    "            assert len(benchmarks[key][name]) == 3, f\"Error, {benchmarks[key][name]}\"\n",
    "        #a = [f\"{benchmarks[key]} {v=} {len(v)=}\" for v in benchmarks[key].values()]\n",
    "        #print(a)\n",
    "    #assert len(benchmarks['256']['kafka']) == 3, \"hmm\"\n",
    "    #print(benchmarks['256']['kafka'])\n",
    "    #print(benchmarks.keys())\n",
    "    \n",
    "        \n",
    "    return benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4257bd-6a6a-4386-a662-d9caf265792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = load_benchmarks(\"HotSpot\", \"DaCapo\")\n",
    "#for gc in [\"Parallel\", \"G1\", \"Z\"]:\n",
    "#for key1 in a:\n",
    "#    assert len(a[key1]) == 3\n",
    "\n",
    "#print(a)\n",
    "#print(a['512'].keys())\n",
    "#print(a['512'].keys())\n",
    "#print(a['256']['tradesoap']['Parallel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0588ac9-e838-43ae-bd84-5a92e8883f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_benchmarks(benchmarks, key, y_label, file_title, layout=None, y_limit=None):\n",
    "    x_labels = list(benchmarks.keys()) # This should be already sorted\n",
    "    print(f\"{x_labels=}\")\n",
    "    x = np.arange(len(x_labels))\n",
    "    fig, ax = plt.subplots(figsize=(20, 10), layout=layout, dpi=300)\n",
    "\n",
    "    gcs = sorted(benchmarks[x_labels[0]])\n",
    "    width = 0.3\n",
    "    multiplier = 0\n",
    "    for gc in gcs:\n",
    "        values = [value[gc][key] for value in benchmarks.values()]\n",
    "        offset = width * multiplier\n",
    "        rects = ax.bar(x + offset, values, width, label=gc)\n",
    "        multiplier += 1\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel(\"Benchmarks\")\n",
    "        ax.set_xticks(x + width, x_labels)\n",
    "        plt.xticks(rotation=45)\n",
    "        ax.legend(ncols=3)\n",
    "        ax.set_ylim(0, y_limit)\n",
    "        #ax.set_title(file_title)\n",
    "        #ax.bar_label(rects, label_type='center')\n",
    "        fig.savefig(f\"graphs/{file_title}.png\")\n",
    "        \n",
    "def find_increment(number):\n",
    "    n = str(number).split(\".\")\n",
    "    num = 1\n",
    "    if n[0] == \"0\":\n",
    "        num = 0.1\n",
    "        for i in n[1]:\n",
    "            num *= 0.1\n",
    "            if i != \"0\":\n",
    "                break\n",
    "    return num\n",
    "\n",
    "    \n",
    "#plt.tight_layout()\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "for runtime, group in itertools.product([\"Graal\", \"HotSpot\"], [\"Renaissance\", \"DaCapo\"]):\n",
    "    benchmarks = load_benchmarks(runtime, group)\n",
    "    for heap_size in benchmarks:\n",
    "        plt.close(\"all\")\n",
    "        max_throughput = max([v2[\"throughput\"] for v1 in benchmarks[heap_size].values() for v2 in v1.values()])\n",
    "        max_latency = max([v2[\"pause_time\"] for v1 in benchmarks[heap_size].values() for v2 in v1.values()])\n",
    "        #print(\"Antes\", max_throughput, max_latency)\n",
    "        max_latency += find_increment(max_latency)\n",
    "        max_throughput += find_increment(max_throughput)\n",
    "        #print(\"Depois\", max_throughput, max_latency)\n",
    "        plot_benchmarks(benchmarks[heap_size], \"throughput\", \"Throughput (seconds)\", f\"{runtime}/{group}/{runtime}-{group}-{heap_size}-throughput\", layout='tight',y_limit=max_throughput)\n",
    "        plot_benchmarks(benchmarks[heap_size], \"pause_time\", \"Pause Time (seconds)\", f\"{runtime}/{group}/{runtime}-{group}-{heap_size}-pause_time\", layout='tight',y_limit=max_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68166d36-0a0b-43ea-b332-2f01fcc2c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_only_success():\n",
    "    benchmarks = {}\n",
    "    for file in Path(\"benchmark_stats/\").glob(\"Renaissance*256*Graal*.json\"):\n",
    "        #print(file)\n",
    "        with open(file) as f: \n",
    "            benchmark = json.loads(f.read())\n",
    "        key = \"error\" if \"error\" in f\"{file}\" else \"success\"\n",
    "        assert benchmark[\"benchmark_name\"] is not None\n",
    "        benchmarks.setdefault(benchmark[\"benchmark_name\"], {}).setdefault(key, []).append(benchmark[\"garbage_collector\"])\n",
    "    import pprint\n",
    "    for key in benchmarks:\n",
    "        if len(benchmarks[key].get(\"success\", {})) == 1:\n",
    "            print(key)\n",
    "find_only_success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993e20b-893a-4622-86c3-bdea1460ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_benchmarks_len_report():\n",
    "    benchmarks = {}\n",
    "    for r in [\"Graal\", \"HotSpot\"]:\n",
    "        for group in [\"DaCapo\", \"Renaissance\"]:\n",
    "            for file in Path(\"benchmark_stats/\").glob(f\"{group}*{r}*.json\"):\n",
    "                with open(file) as f: \n",
    "                    b = json.loads(f.read())\n",
    "                    gc = b[\"garbage_collector\"]\n",
    "                    name = b[\"benchmark_name\"]\n",
    "                    if name == \"spring\":\n",
    "                        print(\"Skipping\")\n",
    "                        continue\n",
    "                    status = \"error\" if bool(b[\"error\"]) else \"success\"\n",
    "                    hs = b[\"heap_size\"]\n",
    "                    entry = benchmarks.setdefault(r, {}).setdefault(hs, {}).setdefault(gc, {}).setdefault(status, [])\n",
    "                    entry.append(name)\n",
    "    nums = {}\n",
    "    for r, h_dict in benchmarks.items():\n",
    "        for heap, gc_dict in h_dict.items():\n",
    "            for gc in gc_dict:\n",
    "                error = gc_dict[gc].get(\"error\", [])\n",
    "                success = gc_dict[gc].get(\"success\", [])\n",
    "                error = len(error)\n",
    "                success = len(success)\n",
    "                gc_dict[gc][\"error\"] = error\n",
    "                gc_dict[gc][\"success\"] = success\n",
    "                nums.setdefault(heap,[]).append(error + success)\n",
    "                \n",
    "    for key in nums:\n",
    "        print(f\"{nums[key]=}\")\n",
    "        assert len(set(nums[key])) == 1\n",
    "    \n",
    "    with open(\"benchmarks_len_report.json\", \"w\") as f:\n",
    "        f.write(json.dumps(benchmarks))\n",
    "    print(benchmarks)\n",
    "compute_benchmarks_len_report()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e22de-087d-4845-aff9-f3f70749e8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
